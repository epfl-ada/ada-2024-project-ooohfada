{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import ldamodel\n",
    "from tqdm import tqdm\n",
    "from gensim import corpora\n",
    "from src.utils.recovery_analysis_utils import str_to_list\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "decline_events = pd.read_csv('data/sampled_decline_events_with_videos.csv')\n",
    "videos = pd.read_csv('data/videos_around_declines.csv')\n",
    "\n",
    "decline_events['Videos_before'] = decline_events['Videos_before'].apply(str_to_list)\n",
    "decline_events['Videos_after'] = decline_events['Videos_after'].apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data_frame with 2 index: the index of the decline and the source (before and after)\n",
    "\n",
    "df_before = decline_events[['Videos_before']].explode('Videos_before')\n",
    "df_before['Source'] = 'Before'\n",
    "df_before = df_before.rename(columns={'Videos_before': 'Video'})\n",
    "\n",
    "df_after = decline_events[['Videos_after']].explode('Videos_after')\n",
    "df_after['Source'] = 'After'\n",
    "df_after = df_after.rename(columns={'Videos_after': 'Video'})\n",
    "\n",
    "df_tags = pd.concat([df_before, df_after], axis=0).reset_index().rename(columns={'index': 'Decline'})\n",
    "df_tags = df_tags.set_index(['Decline', 'Source'])\n",
    "\n",
    "df_tags.sort_values(by = ['Decline', 'Source'])\n",
    "df_tags = df_tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>Before</th>\n",
       "      <td>1684989</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684990</td>\n",
       "      <td>MsRosieBea,primark haul,primark haul august,pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684991</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684992</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684993</td>\n",
       "      <td>MsRosieBea,red lip,get ready with me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>1889699</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889700</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889701</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,lofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889702</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,mell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889703</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,lofi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2069978 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Video                                               Tags\n",
       "Decline Source                                                            \n",
       "0       Before  1684989                                         MsRosieBea\n",
       "        Before  1684990  MsRosieBea,primark haul,primark haul august,pr...\n",
       "        Before  1684991                                         MsRosieBea\n",
       "        Before  1684992                                         MsRosieBea\n",
       "        Before  1684993               MsRosieBea,red lip,get ready with me\n",
       "...                 ...                                                ...\n",
       "36598   After   1889699  Music,beats,instrumental,right beat radio,stra...\n",
       "        After   1889700  Music,beats,instrumental,right beat radio,late...\n",
       "        After   1889701  Music,beats,instrumental,right beat radio,lofi...\n",
       "        After   1889702  Music,beats,instrumental,right beat radio,mell...\n",
       "        After   1889703  Music,beats,instrumental,right beat radio,lofi...\n",
       "\n",
       "[2069978 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map to obtain the tags of all videos for each video before and after decline\n",
    "df_tags['Tags'] = df_tags['Video'].map(lambda video: videos.loc[video, 'tags'] if video in videos.index else None)\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea,back to uni,uni outfits\\nMsRosieBea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea,uni work,studying fashion design,fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,playthrough,blind play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,playthrough,blind play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>After</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36595</th>\n",
       "      <th>Before</th>\n",
       "      <td>Despacito accordion cover,Fonsi Despacito acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36597</th>\n",
       "      <th>After</th>\n",
       "      <td>Shaper,Clapper,Keith Fenner,Fenner,machine sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Bridgeport,Stainless Steel Placards,Roller Kit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,minn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,soul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61194 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined\n",
       "Decline Source                                                   \n",
       "0       After   MsRosieBea,21st birthday,birthday,ring,jewelle...\n",
       "        Before  MsRosieBea,uni work,studying fashion design,fa...\n",
       "1       After   hollow,generationhollow,playthrough,blind play...\n",
       "        Before  hollow,generationhollow,playthrough,blind play...\n",
       "2       After                                                None\n",
       "...                                                           ...\n",
       "36595   Before  Despacito accordion cover,Fonsi Despacito acco...\n",
       "36597   After   Shaper,Clapper,Keith Fenner,Fenner,machine sho...\n",
       "        Before  Bridgeport,Stainless Steel Placards,Roller Kit...\n",
       "36598   After   Music,beats,instrumental,right beat radio,minn...\n",
       "        Before  Music,beats,instrumental,right beat radio,lofi...\n",
       "\n",
       "[61194 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get for each decline only 2 rows with the tags corresponding to the before and the after, handling NaNs and non-list values\n",
    "df_tags = df_tags.groupby(['Decline', 'Source'])['Tags'].apply(\n",
    "    lambda x: list(set([item for sublist in x.dropna() for item in (sublist if isinstance(sublist, list) else [sublist])]))\n",
    ").reset_index(name='Tags_combined')\n",
    "\n",
    "df_tags.set_index(['Decline', 'Source'], inplace=True)\n",
    "\n",
    "# Map the tags to a string, separating them by new lines\n",
    "df_tags['Tags_combined'] = df_tags['Tags_combined'].map(lambda tags: '\\n'.join(tags) if tags else None)\n",
    "\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "CASEFOLD = False\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_str(s):\n",
    "    if not isinstance(s, str) or not s.strip(): # Cases where s = None\n",
    "        return []\n",
    "    tokens = word_tokenize(s.lower() if CASEFOLD else s, preserve_line=True)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "df_small = df_tags.head(100)\n",
    "print(df_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eva\\AppData\\Local\\Temp\\ipykernel_22020\\1432068147.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['Tokens'] = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and lemmatizing tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 211.45it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing and lemmatizing tags\")\n",
    "df_small['Tokens'] = None\n",
    "for index, row in tqdm(df_small.iterrows(), total=df_small.shape[0]):\n",
    "    df_small.at[index, 'Tokens'] = preprocess_str(row['Tags_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary and corpus\n",
      "Training LDA model\n",
      "(17, '0.090*\"Fortnite\" + 0.063*\"fortnite\" + 0.032*\"pokemon\" + 0.029*\"Ninja\" + 0.020*\"voice\" + 0.020*\"real\" + 0.015*\"shiny\" + 0.014*\"montage\" + 0.013*\"challenge\"')\n",
      "(16, '0.000*\"BLACKPINK\" + 0.000*\"DDU\" + 0.000*\"DU\" + 0.000*\"SQUARE\" + 0.000*\"UP\" + 0.000*\"brexit\" + 0.000*\"WW2\" + 0.000*\"블랙핑크\" + 0.000*\"Call\"')\n",
      "(54, '0.034*\"tip\" + 0.026*\"guide\" + 0.024*\"hollow\" + 0.023*\"generationhollow\" + 0.021*\"tutorial\" + 0.020*\"gameplay\" + 0.016*\"trick\" + 0.016*\"playthrough\" + 0.016*\"top\"')\n",
      "(10, '0.049*\"reaction\" + 0.033*\"kpop\" + 0.017*\"BLACKPINK\" + 0.017*\"블랙핑크\" + 0.017*\"blackpink\" + 0.017*\"Shane\" + 0.017*\"shane\" + 0.011*\"house\" + 0.011*\"FANSIGN\"')\n",
      "(32, '0.020*\"impulse\" + 0.007*\"j\" + 0.007*\"cole\" + 0.007*\"drake\" + 0.007*\"prod\" + 0.007*\"uzi\" + 0.007*\"migos\" + 0.007*\"impulsebeats\" + 0.007*\"beatz\"')\n",
      "(33, '0.058*\"brexit\" + 0.033*\"james\" + 0.032*\"o\\'brien\" + 0.021*\"Brexit\" + 0.019*\"uk\" + 0.017*\"post\" + 0.017*\"trump\" + 0.014*\"caller\" + 0.013*\"Johnson\"')\n",
      "(45, '0.016*\"new\" + 0.016*\"model\" + 0.016*\"york\" + 0.016*\"gay\" + 0.011*\"girl\" + 0.011*\"ava\" + 0.011*\"city\" + 0.011*\"modeling\" + 0.011*\"fit\"')\n",
      "(13, '0.031*\"mash\" + 0.029*\"star\" + 0.022*\"spaceballs\" + 0.022*\"deadpool\" + 0.019*\"wayne\" + 0.019*\"trek\" + 0.016*\"war\" + 0.016*\"barf\" + 0.015*\"x\"')\n",
      "(25, '0.007*\"Indivisible\" + 0.007*\"Jon\" + 0.007*\"Manhattan\" + 0.007*\"odette.pavlova\" + 0.007*\"Choice\" + 0.007*\"Bulgari\" + 0.007*\"Rose.\" + 0.007*\"designer\" + 0.007*\"Pure\"')\n",
      "(41, '0.042*\"horse\" + 0.025*\"toy\" + 0.020*\"stormy\" + 0.018*\"strike\" + 0.017*\"model\" + 0.017*\"pony\" + 0.016*\"kid\" + 0.015*\"family\" + 0.013*\"Spirit\"')\n",
      "(12, '0.001*\"fortnite\" + 0.000*\"gameplay\" + 0.000*\"game\" + 0.000*\"skin\" + 0.000*\"android\" + 0.000*\"pc\" + 0.000*\"ps4\" + 0.000*\"samsung\" + 0.000*\"fun\"')\n",
      "(52, '0.073*\"eye\" + 0.072*\"makeup\" + 0.039*\"beauty\" + 0.038*\"cat\" + 0.034*\"tutorial\" + 0.027*\"smokey\" + 0.027*\"ready\" + 0.027*\"get\" + 0.023*\"liner\"')\n",
      "(46, '0.071*\"Games\" + 0.058*\"Video\" + 0.028*\"Game\" + 0.028*\"Gaming\" + 0.028*\"Rerez\" + 0.025*\"Gamers\" + 0.022*\"Bad\" + 0.018*\"Review\" + 0.016*\"Nintendo\"')\n",
      "(31, '0.028*\"whats\" + 0.028*\"inside\" + 0.026*\"hello\" + 0.026*\"tutorial\" + 0.026*\"DIY\" + 0.026*\"beauty\" + 0.026*\"decoden\" + 0.026*\"kawaii\" + 0.026*\"polymer\"')\n",
      "(36, '0.032*\"urdu\" + 0.023*\"youtube\" + 0.022*\"opener\" + 0.020*\"illuminati\" + 0.018*\"hindi\" + 0.018*\"tv\" + 0.017*\"time\" + 0.017*\"space\" + 0.014*\"poem\"')\n",
      "(0, '0.054*\"game\" + 0.051*\"video\" + 0.051*\"Continue\" + 0.048*\"let\" + 0.027*\"episode\" + 0.027*\"gameplay\" + 0.027*\"funny\" + 0.027*\"play\" + 0.026*\"playthrough\"')\n",
      "(18, '0.001*\"van\" + 0.001*\"life\" + 0.001*\"Wander\" + 0.000*\"Corbin\" + 0.000*\"baby\" + 0.000*\"pregnancy\" + 0.000*\"Kelsey\" + 0.000*\"house\" + 0.000*\"new\"')\n",
      "(27, '0.033*\"Sega\" + 0.030*\"Games\" + 0.028*\"Game\" + 0.026*\"Gaming\" + 0.026*\"Review\" + 0.026*\"Boy\" + 0.023*\"Video\" + 0.023*\"Reviews\" + 0.023*\"Rerez\"')\n",
      "(21, '0.050*\"best\" + 0.046*\"moment\" + 0.044*\"funny\" + 0.023*\"base\" + 0.023*\"survival\" + 0.022*\"series\" + 0.021*\"solo\" + 0.020*\"loot\" + 0.019*\"stimpee\"')\n",
      "(42, '0.049*\"Fortnite\" + 0.035*\"fortnite\" + 0.025*\"moment\" + 0.023*\"Ninja\" + 0.022*\"\\'s\" + 0.022*\"real\" + 0.021*\"voice\" + 0.019*\"America\" + 0.019*\"talent\"')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea,21st birthday,birthday,ring,jewelle...</td>\n",
       "      <td>[MsRosieBea,21st, birthday, birthday, ring, je...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.399864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea,uni work,studying fashion design,fa...</td>\n",
       "      <td>[MsRosieBea, uni, work, studying, fashion, des...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.986550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,playthrough,blind play...</td>\n",
       "      <td>[hollow, generationhollow, playthrough, blind,...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.998292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,playthrough,blind play...</td>\n",
       "      <td>[hollow, generationhollow, playthrough, blind,...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.996498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>After</th>\n",
       "      <td>dayz,dayz standalone,.62,update,map,loot,inter...</td>\n",
       "      <td>[dayz, dayz, standalone, .62, update, map, loo...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.899641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">55</th>\n",
       "      <th>After</th>\n",
       "      <td>Brexit,Boris Johnson,PM,Boris,no deal,brexitee...</td>\n",
       "      <td>[Brexit, Boris, Johnson, PM, Boris, deal, brex...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>james o'brien,james o'brien brexit,brexit disa...</td>\n",
       "      <td>[james, o'brien, james, o'brien, brexit, brexi...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">57</th>\n",
       "      <th>After</th>\n",
       "      <td>base de rap,pista de rap,hip hop instrumental,...</td>\n",
       "      <td>[base, de, rap, pista, de, rap, hip, hop, inst...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.997112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>witch house type beat,A$AP rocky type,Suicide ...</td>\n",
       "      <td>[witch, house, type, beat, A, AP, rocky, type,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.997988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <th>After</th>\n",
       "      <td>plan with me,erin condren,life planner,2019,20...</td>\n",
       "      <td>[plan, erin, condren, life, planner,2019,2020,...</td>\n",
       "      <td>44</td>\n",
       "      <td>0.988968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined  \\\n",
       "Decline Source                                                      \n",
       "0       After   MsRosieBea,21st birthday,birthday,ring,jewelle...   \n",
       "        Before  MsRosieBea,uni work,studying fashion design,fa...   \n",
       "1       After   hollow,generationhollow,playthrough,blind play...   \n",
       "        Before  hollow,generationhollow,playthrough,blind play...   \n",
       "3       After   dayz,dayz standalone,.62,update,map,loot,inter...   \n",
       "...                                                           ...   \n",
       "55      After   Brexit,Boris Johnson,PM,Boris,no deal,brexitee...   \n",
       "        Before  james o'brien,james o'brien brexit,brexit disa...   \n",
       "57      After   base de rap,pista de rap,hip hop instrumental,...   \n",
       "        Before  witch house type beat,A$AP rocky type,Suicide ...   \n",
       "58      After   plan with me,erin condren,life planner,2019,20...   \n",
       "\n",
       "                                                           Tokens  \\\n",
       "Decline Source                                                      \n",
       "0       After   [MsRosieBea,21st, birthday, birthday, ring, je...   \n",
       "        Before  [MsRosieBea, uni, work, studying, fashion, des...   \n",
       "1       After   [hollow, generationhollow, playthrough, blind,...   \n",
       "        Before  [hollow, generationhollow, playthrough, blind,...   \n",
       "3       After   [dayz, dayz, standalone, .62, update, map, loo...   \n",
       "...                                                           ...   \n",
       "55      After   [Brexit, Boris, Johnson, PM, Boris, deal, brex...   \n",
       "        Before  [james, o'brien, james, o'brien, brexit, brexi...   \n",
       "57      After   [base, de, rap, pista, de, rap, hip, hop, inst...   \n",
       "        Before  [witch, house, type, beat, A, AP, rocky, type,...   \n",
       "58      After   [plan, erin, condren, life, planner,2019,2020,...   \n",
       "\n",
       "                Dominant_Topic  Topic_Probability  \n",
       "Decline Source                                     \n",
       "0       After               35           0.399864  \n",
       "        Before              35           0.986550  \n",
       "1       After               17           0.998292  \n",
       "        Before              17           0.996498  \n",
       "3       After               31           0.899641  \n",
       "...                        ...                ...  \n",
       "55      After                6           0.999234  \n",
       "        Before               6           0.999397  \n",
       "57      After               16           0.997112  \n",
       "        Before              16           0.997988  \n",
       "58      After               44           0.988968  \n",
       "\n",
       "[86 rows x 4 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary and a corpus for the LDA model\n",
    "print(\"Creating dictionary and corpus\")\n",
    "dictionary = corpora.Dictionary(df_small['Tokens'])\n",
    "corpus = [dictionary.doc2bow(token_list) for token_list in df_small['Tokens']]\n",
    "\n",
    "print(\"Training LDA model\")\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=55, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = lda.print_topics(num_words=9)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning topics to each document\n",
      "                                                    Tags_combined  \\\n",
      "Decline Source                                                      \n",
      "0       After   MsRosieBea,21st birthday,birthday,ring,jewelle...   \n",
      "        Before  MsRosieBea,uni work,studying fashion design,fa...   \n",
      "1       After   hollow,generationhollow,playthrough,blind play...   \n",
      "        Before  hollow,generationhollow,playthrough,blind play...   \n",
      "3       After   dayz,dayz standalone,.62,update,map,loot,inter...   \n",
      "        Before  dayz,dayz standalone,.62,update,map,loot,inter...   \n",
      "4       After   Halloween,spooky,scary,creepy,Bogeyman,Breyer,...   \n",
      "        Before  HoneyheartsC,MyFroggyStuff,Infinity Breyers,da...   \n",
      "5       After   Triple Entray,Phora,Drake,Eminem,Justin Bieber...   \n",
      "        Before  Hip hop,Triple Entray,Drake,Eminem,Logic,Phora...   \n",
      "7       After   Yasha,Yasha Jeltuhin,Cyr,Cyr Wheel,Circus,Akro...   \n",
      "        Before  Yasha,Yasha Jeltuhin,Akrosphere,Circus,Jen Mac...   \n",
      "8       After   bruce lee,asian trap beat,chinese trap beat,88...   \n",
      "        Before  impulsebeats,yung impulse,impulse beats,impuls...   \n",
      "10      After   Family vlogs,daily vlogs,toddler,cute couple,n...   \n",
      "        Before  emergency,tornado,driving through a tornado,ca...   \n",
      "11      After   pharmit,pharmit24,malaysia,awesome,gamer,youtu...   \n",
      "        Before  pharmit,pharmit24,malaysia,awesome,gamer,youtu...   \n",
      "12      After   twintalksballet,twin,twins,talk,talks,ballet,b...   \n",
      "        Before  twintalksballet,twin,twins,talk,talks,ballet,b...   \n",
      "\n",
      "                                                           Tokens  \\\n",
      "Decline Source                                                      \n",
      "0       After   [MsRosieBea,21st, birthday, birthday, ring, je...   \n",
      "        Before  [MsRosieBea, uni, work, studying, fashion, des...   \n",
      "1       After   [hollow, generationhollow, playthrough, blind,...   \n",
      "        Before  [hollow, generationhollow, playthrough, blind,...   \n",
      "3       After   [dayz, dayz, standalone, .62, update, map, loo...   \n",
      "        Before  [dayz, dayz, standalone, .62, update, map, loo...   \n",
      "4       After   [Halloween, spooky, scary, creepy, Bogeyman, B...   \n",
      "        Before  [HoneyheartsC, MyFroggyStuff, Infinity, Breyer...   \n",
      "5       After   [Triple, Entray, Phora, Drake, Eminem, Justin,...   \n",
      "        Before  [Hip, hop, Triple, Entray, Drake, Eminem, Logi...   \n",
      "7       After   [Yasha, Yasha, Jeltuhin, Cyr, Cyr, Wheel, Circ...   \n",
      "        Before  [Yasha, Yasha, Jeltuhin, Akrosphere, Circus, J...   \n",
      "8       After   [bruce, lee, asian, trap, beat, chinese, trap,...   \n",
      "        Before  [impulsebeats, yung, impulse, impulse, beat, i...   \n",
      "10      After   [Family, vlogs, daily, vlogs, toddler, cute, c...   \n",
      "        Before  [emergency, tornado, driving, tornado, car, v,...   \n",
      "11      After   [pharmit, pharmit24, malaysia, awesome, gamer,...   \n",
      "        Before  [pharmit, pharmit24, malaysia, awesome, gamer,...   \n",
      "12      After   [twintalksballet, twin, twin, talk, talk, ball...   \n",
      "        Before  [twintalksballet, twin, twin, talk, talk, ball...   \n",
      "\n",
      "                Dominant_Topic  Topic_Probability  \n",
      "Decline Source                                     \n",
      "0       After               40           0.960726  \n",
      "        Before              33           0.758448  \n",
      "1       After               54           0.713057  \n",
      "        Before              54           0.963160  \n",
      "3       After               21           0.999240  \n",
      "        Before              21           0.999116  \n",
      "4       After               35           0.919800  \n",
      "        Before              41           0.999340  \n",
      "5       After               36           0.601828  \n",
      "        Before              36           0.987081  \n",
      "7       After               43           0.968326  \n",
      "        Before              29           0.945451  \n",
      "8       After               19           0.993182  \n",
      "        Before              19           0.542273  \n",
      "10      After               11           0.999820  \n",
      "        Before              11           0.999817  \n",
      "11      After                6           0.974626  \n",
      "        Before               6           0.999218  \n",
      "12      After               53           0.639136  \n",
      "        Before              53           0.997409  \n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning topics to each document\")\n",
    "\n",
    "# Assign the dominant topic to each document\n",
    "def assign_dominant_topic(tokens, lda_model, dictionary):\n",
    "    if not tokens or not isinstance(tokens, list):  # Handle empty or invalid tokens\n",
    "        return None, None\n",
    "    bow = dictionary.doc2bow(tokens)  # Convert tokens to bag-of-words format\n",
    "    topic_probs = lda_model.get_document_topics(bow)  # Get topic distribution\n",
    "    if topic_probs:\n",
    "        dominant_topic, prob = max(topic_probs, key=lambda x: x[1])  # Most probable topic\n",
    "        return dominant_topic, prob\n",
    "    return None, None\n",
    "\n",
    "df_small['Dominant_Topic'], df_small['Topic_Probability'] = zip(\n",
    "    *df_small['Tokens'].apply(lambda tokens: assign_dominant_topic(tokens, lda, dictionary))\n",
    ")\n",
    "\n",
    "print(df_small.head(20))\n",
    "df_small.to_csv('df_small_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create two columns [Topic_change] and [Tokens_change] to determine if there is a difference between the tags before and after a decline. A change in tokens is used for granular analysis while a change is topics is more appropriate for detecting higher-level patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MsRosieBea,21st birthday birthday ring jewelle...</td>\n",
       "      <td>MsRosieBea uni work studying fashion design fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Halloween spooky scary creepy Bogeyman Breyer ...</td>\n",
       "      <td>HoneyheartsC MyFroggyStuff Infinity Breyers da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Triple Entray Phora Drake Eminem Justin Bieber...</td>\n",
       "      <td>Hip hop Triple Entray Drake Eminem Logic Phora...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 40.0   33.0   \n",
       "1                 54.0   54.0   \n",
       "3                 21.0   21.0   \n",
       "4                 35.0   41.0   \n",
       "5                 36.0   36.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        MsRosieBea,21st birthday birthday ring jewelle...   \n",
       "1        hollow generationhollow playthrough blind play...   \n",
       "3        dayz dayz standalone .62 update map loot inter...   \n",
       "4        Halloween spooky scary creepy Bogeyman Breyer ...   \n",
       "5        Triple Entray Phora Drake Eminem Justin Bieber...   \n",
       "\n",
       "                                                            \n",
       "Source                                              Before  \n",
       "Decline                                                     \n",
       "0        MsRosieBea uni work studying fashion design fa...  \n",
       "1        hollow generationhollow playthrough blind play...  \n",
       "3        dayz dayz standalone .62 update map loot inter...  \n",
       "4        HoneyheartsC MyFroggyStuff Infinity Breyers da...  \n",
       "5        Hip hop Triple Entray Drake Eminem Logic Phora...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df_small.dropna(subset=['Tokens', 'Dominant_Topic'])\n",
    "\n",
    "# Pivot the dataset, keeping 'Dominant_topic' in a separate column\n",
    "df_pivot = df_small.pivot_table(\n",
    "    index='Decline',  # The index will be based on the 'Decline'\n",
    "    columns='Source',  # We are splitting by 'Source' (Before and After)\n",
    "    values=['Tokens', 'Dominant_Topic'],  # We want both Tokens and Dominant_topic in the pivoted table\n",
    "    aggfunc={\n",
    "        'Tokens': lambda x: ' '.join([item for sublist in x for item in sublist]),  # Flatten and join the tokens\n",
    "        'Dominant_Topic': lambda x: x.mode()[0]  # Get the most frequent dominant topic (mode)\n",
    "    }\n",
    ")\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "      <th>Token_Change</th>\n",
       "      <th>Topic_Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MsRosieBea,21st birthday birthday ring jewelle...</td>\n",
       "      <td>MsRosieBea uni work studying fashion design fa...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Halloween spooky scary creepy Bogeyman Breyer ...</td>\n",
       "      <td>HoneyheartsC MyFroggyStuff Infinity Breyers da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Triple Entray Phora Drake Eminem Justin Bieber...</td>\n",
       "      <td>Hip hop Triple Entray Drake Eminem Logic Phora...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 40.0   33.0   \n",
       "1                 54.0   54.0   \n",
       "3                 21.0   21.0   \n",
       "4                 35.0   41.0   \n",
       "5                 36.0   36.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        MsRosieBea,21st birthday birthday ring jewelle...   \n",
       "1        hollow generationhollow playthrough blind play...   \n",
       "3        dayz dayz standalone .62 update map loot inter...   \n",
       "4        Halloween spooky scary creepy Bogeyman Breyer ...   \n",
       "5        Triple Entray Phora Drake Eminem Justin Bieber...   \n",
       "\n",
       "                                                           Token_Change  \\\n",
       "Source                                              Before                \n",
       "Decline                                                                   \n",
       "0        MsRosieBea uni work studying fashion design fa...        False   \n",
       "1        hollow generationhollow playthrough blind play...        False   \n",
       "3        dayz dayz standalone .62 update map loot inter...        False   \n",
       "4        HoneyheartsC MyFroggyStuff Infinity Breyers da...        False   \n",
       "5        Hip hop Triple Entray Drake Eminem Logic Phora...        False   \n",
       "\n",
       "        Topic_Change  \n",
       "Source                \n",
       "Decline               \n",
       "0               True  \n",
       "1              False  \n",
       "3              False  \n",
       "4               True  \n",
       "5              False  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_change(tokens_before, tokens_after):\n",
    "    # Ensure tokens are lists and not NaN or float\n",
    "    if not isinstance(tokens_before, list):\n",
    "        tokens_before = []\n",
    "    if not isinstance(tokens_after, list):\n",
    "        tokens_after = []\n",
    "        \n",
    "    # Compare sets of tokens\n",
    "    set_before = set(tokens_before)\n",
    "    set_after = set(tokens_after)\n",
    "    return set_before != set_after  # Change if the sets are not identical\n",
    "\n",
    "# Apply the token change function to compare the tokens before and after for each decline\n",
    "df_pivot['Token_Change'] = df_pivot.apply(\n",
    "    lambda row: token_change(row[('Tokens', 'Before')], row[('Tokens', 'After')]), axis=1)\n",
    "\n",
    "# Assuming 'Dominant_topic' columns are available for 'Before' and 'After'\n",
    "df_pivot['Topic_Change'] = df_pivot.apply(\n",
    "    lambda row: row[('Dominant_Topic', 'Before')] != row[('Dominant_Topic', 'After')], axis=1)\n",
    "\n",
    "# Verify the results\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.7474957968694171\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=df_small['Tokens'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}') # 0.7475 with 55 topics, numwords = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and lemmatizing tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61194/61194 [11:13<00:00, 90.83it/s] \n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing and lemmatizing tags\")\n",
    "df_tags['Tokens'] = None\n",
    "for index, row in tqdm(df_tags.iterrows(), total=df_tags.shape[0]):\n",
    "    df_tags.at[index, 'Tokens'] = preprocess_str(row['Tags_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary and corpus\n",
      "Training LDA model\n",
      "(36, '0.197*\"2017\" + 0.108*\"music\" + 0.045*\"house\" + 0.034*\"2016\" + 0.031*\"mix\" + 0.029*\"best\" + 0.029*\"dubstep\" + 0.026*\"2018\" + 0.024*\"Music\"')\n",
      "(34, '0.313*\"world\" + 0.090*\"World\" + 0.033*\"fire\" + 0.029*\"tank\" + 0.020*\"gun\" + 0.015*\"combat\" + 0.014*\"force\" + 0.012*\"three\" + 0.011*\"kodi\"')\n",
      "(16, '0.196*\"design\" + 0.076*\"simple\" + 0.072*\"dot\" + 0.062*\"easy\" + 0.046*\"nail\" + 0.041*\"hand\" + 0.029*\"small\" + 0.027*\"hd\" + 0.021*\"without\"')\n",
      "(3, '0.058*\"season\" + 0.042*\"6\" + 0.038*\"clash\" + 0.032*\"episode\" + 0.029*\"7\" + 0.024*\"10\" + 0.023*\"1\" + 0.020*\"royale\" + 0.020*\"top\"')\n",
      "(15, '0.176*\"news\" + 0.037*\"hindi\" + 0.034*\"video\" + 0.032*\"latest\" + 0.022*\"live\" + 0.022*\"today\" + 0.021*\"2019\" + 0.020*\"india\" + 0.020*\"mp\"')\n",
      "(49, '0.070*\"vlog\" + 0.055*\"family\" + 0.026*\"vlogs\" + 0.025*\"daily\" + 0.020*\"life\" + 0.020*\"vlogger\" + 0.019*\"baby\" + 0.018*\"day\" + 0.014*\"mom\"')\n",
      "(5, '0.043*\"black\" + 0.036*\"zombie\" + 0.035*\"ops\" + 0.035*\"4\" + 0.032*\"call\" + 0.031*\"3\" + 0.030*\"cod\" + 0.029*\"duty\" + 0.026*\"ww2\"')\n",
      "(30, '0.202*\"fortnite\" + 0.042*\"battle\" + 0.032*\"royale\" + 0.029*\"overwatch\" + 0.027*\"skin\" + 0.026*\"new\" + 0.018*\"moment\" + 0.018*\"Fortnite\" + 0.016*\"funny\"')\n",
      "(23, '0.155*\"v\" + 0.065*\"2018\" + 0.052*\"2019\" + 0.032*\"League\" + 0.025*\"cricket\" + 0.022*\"cup\" + 0.022*\"sport\" + 0.017*\"Cricket\" + 0.017*\"highlight\"')\n",
      "(39, '0.107*\"Pokemon\" + 0.072*\"slime\" + 0.030*\"God\" + 0.026*\"Shiny\" + 0.025*\"Moon\" + 0.024*\"Jesus\" + 0.020*\"Sun\" + 0.016*\"Spirit\" + 0.015*\"Bible\"')\n",
      "(21, '0.054*\"deck\" + 0.048*\"wow\" + 0.039*\"magic\" + 0.036*\"Clash\" + 0.030*\"arena\" + 0.027*\"warcraft\" + 0.025*\"card\" + 0.022*\"hearthstone\" + 0.021*\"Royale\"')\n",
      "(54, '0.252*\"News\" + 0.226*\"Live\" + 0.071*\"Channel\" + 0.031*\"Vape\" + 0.018*\"24\" + 0.016*\"Bangla\" + 0.014*\"HUT\" + 0.012*\"ASUS\" + 0.010*\"spoofing\"')\n",
      "(14, '0.061*\"2\" + 0.043*\"dota\" + 0.038*\"highlight\" + 0.034*\"Dota\" + 0.034*\"moment\" + 0.032*\"pubg\" + 0.030*\"twitch\" + 0.029*\"stream\" + 0.029*\"gameplay\"')\n",
      "(17, '0.138*\"beat\" + 0.103*\"type\" + 0.085*\"free\" + 0.037*\"trap\" + 0.029*\"rap\" + 0.026*\"2018\" + 0.019*\"instrumental\" + 0.018*\"hop\" + 0.018*\"lil\"')\n",
      "(25, '0.046*\"dragon\" + 0.044*\"ball\" + 0.040*\"smash\" + 0.029*\"ultimate\" + 0.028*\"Summit\" + 0.027*\"super\" + 0.025*\"battle\" + 0.023*\"anime\" + 0.019*\"dokkan\"')\n",
      "(48, '0.051*\"nintendo\" + 0.046*\"switch\" + 0.034*\"Nintendo\" + 0.029*\"Smash\" + 0.026*\"mario\" + 0.024*\"Switch\" + 0.024*\"xbox\" + 0.019*\"Super\" + 0.016*\"Mario\"')\n",
      "(24, '0.131*\"game\" + 0.054*\"gameplay\" + 0.042*\"play\" + 0.030*\"let\" + 0.030*\"\\'s\" + 0.021*\"gaming\" + 0.018*\"walkthrough\" + 0.015*\"part\" + 0.013*\"video\"')\n",
      "(20, '0.019*\"trump\" + 0.011*\"time\" + 0.010*\"magazine\" + 0.009*\"news\" + 0.008*\"Farage\" + 0.008*\"politics\" + 0.007*\"medium\" + 0.007*\"science\" + 0.007*\"donald\"')\n",
      "(45, '0.030*\"Gameplay\" + 0.029*\"Game\" + 0.025*\"The\" + 0.019*\"Gaming\" + 0.017*\"Play\" + 0.014*\"\\'s\" + 0.014*\"2\" + 0.013*\"New\" + 0.013*\"Games\"')\n",
      "(27, '0.038*\"PGT\" + 0.033*\"football\" + 0.033*\"league\" + 0.021*\"goal\" + 0.020*\"de\" + 0.019*\"boxing\" + 0.016*\"city\" + 0.015*\"cup\" + 0.014*\"sport\"')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary and a corpus for the LDA model\n",
    "print(\"Creating dictionary and corpus\")\n",
    "dictionary = corpora.Dictionary(df_tags['Tokens'])\n",
    "corpus = [dictionary.doc2bow(token_list) for token_list in df_tags['Tokens']]\n",
    "\n",
    "print(\"Training LDA model\")\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=55, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = lda.print_topics(num_words=9)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning topics to each document\n",
      "                                                    Tags_combined  \\\n",
      "Decline Source                                                      \n",
      "0       After   MsRosieBea,21st birthday,birthday,ring,jewelle...   \n",
      "        Before  MsRosieBea,uni work,studying fashion design,fa...   \n",
      "1       After   hollow,generationhollow,playthrough,blind play...   \n",
      "        Before  hollow,generationhollow,playthrough,blind play...   \n",
      "2       After                                                None   \n",
      "        Before                                               None   \n",
      "3       After   dayz,dayz standalone,.62,update,map,loot,inter...   \n",
      "        Before  dayz,dayz standalone,.62,update,map,loot,inter...   \n",
      "4       After   Halloween,spooky,scary,creepy,Bogeyman,Breyer,...   \n",
      "        Before  HoneyheartsC,MyFroggyStuff,Infinity Breyers,da...   \n",
      "5       After   Triple Entray,Phora,Drake,Eminem,Justin Bieber...   \n",
      "        Before  Hip hop,Triple Entray,Drake,Eminem,Logic,Phora...   \n",
      "7       After   Yasha,Yasha Jeltuhin,Cyr,Cyr Wheel,Circus,Akro...   \n",
      "        Before  Yasha,Yasha Jeltuhin,Akrosphere,Circus,Jen Mac...   \n",
      "8       After   bruce lee,asian trap beat,chinese trap beat,88...   \n",
      "        Before  impulsebeats,yung impulse,impulse beats,impuls...   \n",
      "9       After                                                None   \n",
      "        Before                                               None   \n",
      "10      After   Family vlogs,daily vlogs,toddler,cute couple,n...   \n",
      "        Before  emergency,tornado,driving through a tornado,ca...   \n",
      "\n",
      "                                                           Tokens  \\\n",
      "Decline Source                                                      \n",
      "0       After   [MsRosieBea,21st, birthday, birthday, ring, je...   \n",
      "        Before  [MsRosieBea, uni, work, studying, fashion, des...   \n",
      "1       After   [hollow, generationhollow, playthrough, blind,...   \n",
      "        Before  [hollow, generationhollow, playthrough, blind,...   \n",
      "2       After                                                  []   \n",
      "        Before                                                 []   \n",
      "3       After   [dayz, dayz, standalone, .62, update, map, loo...   \n",
      "        Before  [dayz, dayz, standalone, .62, update, map, loo...   \n",
      "4       After   [Halloween, spooky, scary, creepy, Bogeyman, B...   \n",
      "        Before  [HoneyheartsC, MyFroggyStuff, Infinity, Breyer...   \n",
      "5       After   [Triple, Entray, Phora, Drake, Eminem, Justin,...   \n",
      "        Before  [Hip, hop, Triple, Entray, Drake, Eminem, Logi...   \n",
      "7       After   [Yasha, Yasha, Jeltuhin, Cyr, Cyr, Wheel, Circ...   \n",
      "        Before  [Yasha, Yasha, Jeltuhin, Akrosphere, Circus, J...   \n",
      "8       After   [bruce, lee, asian, trap, beat, chinese, trap,...   \n",
      "        Before  [impulsebeats, yung, impulse, impulse, beat, i...   \n",
      "9       After                                                  []   \n",
      "        Before                                                 []   \n",
      "10      After   [Family, vlogs, daily, vlogs, toddler, cute, c...   \n",
      "        Before  [emergency, tornado, driving, tornado, car, v,...   \n",
      "\n",
      "                Dominant_Topic  Topic_Probability  \n",
      "Decline Source                                     \n",
      "0       After             49.0           0.753898  \n",
      "        Before            42.0           0.515696  \n",
      "1       After             24.0           0.452430  \n",
      "        Before            24.0           0.280239  \n",
      "2       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "3       After             35.0           0.339141  \n",
      "        Before            35.0           0.393435  \n",
      "4       After             28.0           0.229987  \n",
      "        Before            40.0           0.216113  \n",
      "5       After             13.0           0.523140  \n",
      "        Before            46.0           0.470104  \n",
      "7       After             13.0           0.901702  \n",
      "        Before            13.0           0.803430  \n",
      "8       After             17.0           0.775420  \n",
      "        Before            17.0           0.815900  \n",
      "9       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "10      After             49.0           0.625696  \n",
      "        Before            49.0           0.439406  \n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning topics to each document\")\n",
    "\n",
    "def assign_dominant_topic(tokens, lda_model, dictionary):\n",
    "    if not tokens or not isinstance(tokens, list):  # Handle empty or invalid tokens\n",
    "        return None, None\n",
    "    bow = dictionary.doc2bow(tokens)  # Convert tokens to bag-of-words format\n",
    "    topic_probs = lda_model.get_document_topics(bow)  # Get topic distribution\n",
    "    if topic_probs:\n",
    "        dominant_topic, prob = max(topic_probs, key=lambda x: x[1])  # Most probable topic\n",
    "        return dominant_topic, prob\n",
    "    return None, None\n",
    "\n",
    "df_tags['Dominant_Topic'], df_tags['Topic_Probability'] = zip(\n",
    "    *df_tags['Tokens'].apply(lambda tokens: assign_dominant_topic(tokens, lda, dictionary))\n",
    ")\n",
    "\n",
    "print(df_tags.head(20))\n",
    "df_tags.to_csv('df_small_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>MsRosieBea,21st birthday birthday ring jewelle...</td>\n",
       "      <td>MsRosieBea uni work studying fashion design fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Halloween spooky scary creepy Bogeyman Breyer ...</td>\n",
       "      <td>HoneyheartsC MyFroggyStuff Infinity Breyers da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Triple Entray Phora Drake Eminem Justin Bieber...</td>\n",
       "      <td>Hip hop Triple Entray Drake Eminem Logic Phora...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 49.0   42.0   \n",
       "1                 24.0   24.0   \n",
       "3                 35.0   35.0   \n",
       "4                 28.0   40.0   \n",
       "5                 13.0   46.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        MsRosieBea,21st birthday birthday ring jewelle...   \n",
       "1        hollow generationhollow playthrough blind play...   \n",
       "3        dayz dayz standalone .62 update map loot inter...   \n",
       "4        Halloween spooky scary creepy Bogeyman Breyer ...   \n",
       "5        Triple Entray Phora Drake Eminem Justin Bieber...   \n",
       "\n",
       "                                                            \n",
       "Source                                              Before  \n",
       "Decline                                                     \n",
       "0        MsRosieBea uni work studying fashion design fa...  \n",
       "1        hollow generationhollow playthrough blind play...  \n",
       "3        dayz dayz standalone .62 update map loot inter...  \n",
       "4        HoneyheartsC MyFroggyStuff Infinity Breyers da...  \n",
       "5        Hip hop Triple Entray Drake Eminem Logic Phora...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags = df_tags.dropna(subset=['Tokens', 'Dominant_Topic'])\n",
    "\n",
    "# Pivot the dataset\n",
    "df_pivot = df_tags.pivot_table(\n",
    "    index='Decline',  \n",
    "    columns='Source',  \n",
    "    values=['Tokens', 'Dominant_Topic'],  \n",
    "    aggfunc={\n",
    "        'Tokens': lambda x: ' '.join([item for sublist in x for item in sublist]),  # Flatten and join the tokens\n",
    "        'Dominant_Topic': lambda x: x.mode()[0]  # Get the most frequent dominant topic\n",
    "    }\n",
    ")\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "      <th>Token_Change</th>\n",
       "      <th>Topic_Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>MsRosieBea,21st birthday birthday ring jewelle...</td>\n",
       "      <td>MsRosieBea uni work studying fashion design fa...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "      <td>dayz dayz standalone .62 update map loot inter...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Halloween spooky scary creepy Bogeyman Breyer ...</td>\n",
       "      <td>HoneyheartsC MyFroggyStuff Infinity Breyers da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Triple Entray Phora Drake Eminem Justin Bieber...</td>\n",
       "      <td>Hip hop Triple Entray Drake Eminem Logic Phora...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 49.0   42.0   \n",
       "1                 24.0   24.0   \n",
       "3                 35.0   35.0   \n",
       "4                 28.0   40.0   \n",
       "5                 13.0   46.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        MsRosieBea,21st birthday birthday ring jewelle...   \n",
       "1        hollow generationhollow playthrough blind play...   \n",
       "3        dayz dayz standalone .62 update map loot inter...   \n",
       "4        Halloween spooky scary creepy Bogeyman Breyer ...   \n",
       "5        Triple Entray Phora Drake Eminem Justin Bieber...   \n",
       "\n",
       "                                                           Token_Change  \\\n",
       "Source                                              Before                \n",
       "Decline                                                                   \n",
       "0        MsRosieBea uni work studying fashion design fa...        False   \n",
       "1        hollow generationhollow playthrough blind play...        False   \n",
       "3        dayz dayz standalone .62 update map loot inter...        False   \n",
       "4        HoneyheartsC MyFroggyStuff Infinity Breyers da...        False   \n",
       "5        Hip hop Triple Entray Drake Eminem Logic Phora...        False   \n",
       "\n",
       "        Topic_Change  \n",
       "Source                \n",
       "Decline               \n",
       "0               True  \n",
       "1              False  \n",
       "3              False  \n",
       "4               True  \n",
       "5               True  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_change(tokens_before, tokens_after):\n",
    "    # Ensure tokens are lists and not NaN or float\n",
    "    if not isinstance(tokens_before, list):\n",
    "        tokens_before = []\n",
    "    if not isinstance(tokens_after, list):\n",
    "        tokens_after = []\n",
    "        \n",
    "    set_before = set(tokens_before)\n",
    "    set_after = set(tokens_after)\n",
    "    return set_before != set_after \n",
    "\n",
    "df_pivot['Token_Change'] = df_pivot.apply(\n",
    "    lambda row: token_change(row[('Tokens', 'Before')], row[('Tokens', 'After')]), axis=1)\n",
    "\n",
    "df_pivot['Topic_Change'] = df_pivot.apply(\n",
    "    lambda row: row[('Dominant_Topic', 'Before')] != row[('Dominant_Topic', 'After')], axis=1)\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a new csv file \n",
    "df_topic_change = df_pivot.reset_index()\n",
    "df_topic_change = df_topic_change[['Decline', 'Topic_Change']]\n",
    "df_topic_change.to_csv('df_topic_change.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.6525009067075975\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=df_tags['Tokens'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}')\n",
    "# small df: 0.7475 with 55 topics, numwords = 9 \n",
    "# whole df: 0.6525 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
