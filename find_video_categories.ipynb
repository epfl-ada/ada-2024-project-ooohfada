{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import ldamodel\n",
    "from tqdm import tqdm\n",
    "from gensim import corpora\n",
    "from src.utils.recovery_analysis_utils import str_to_list\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "decline_events = pd.read_csv('data/sampled_decline_events_with_videos.csv')\n",
    "videos = pd.read_csv('data/videos_around_declines.csv')\n",
    "\n",
    "decline_events['Videos_before'] = decline_events['Videos_before'].apply(str_to_list)\n",
    "decline_events['Videos_after'] = decline_events['Videos_after'].apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data_frame with 2 index: the index of the decline and the source (before and after)\n",
    "\n",
    "df_before = decline_events[['Videos_before']].explode('Videos_before')\n",
    "df_before['Source'] = 'Before'\n",
    "df_before = df_before.rename(columns={'Videos_before': 'Video'})\n",
    "\n",
    "df_after = decline_events[['Videos_after']].explode('Videos_after')\n",
    "df_after['Source'] = 'After'\n",
    "df_after = df_after.rename(columns={'Videos_after': 'Video'})\n",
    "\n",
    "df_tags = pd.concat([df_before, df_after], axis=0).reset_index().rename(columns={'index': 'Decline'})\n",
    "df_tags = df_tags.set_index(['Decline', 'Source'])\n",
    "\n",
    "df_tags.sort_values(by = ['Decline', 'Source'])\n",
    "df_tags = df_tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>Before</th>\n",
       "      <td>1684989</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684990</td>\n",
       "      <td>MsRosieBea,primark haul,primark haul august,pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684991</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684992</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684993</td>\n",
       "      <td>MsRosieBea,red lip,get ready with me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>1889699</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889700</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889701</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,lofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889702</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,mell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889703</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,lofi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2069978 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Video                                               Tags\n",
       "Decline Source                                                            \n",
       "0       Before  1684989                                         MsRosieBea\n",
       "        Before  1684990  MsRosieBea,primark haul,primark haul august,pr...\n",
       "        Before  1684991                                         MsRosieBea\n",
       "        Before  1684992                                         MsRosieBea\n",
       "        Before  1684993               MsRosieBea,red lip,get ready with me\n",
       "...                 ...                                                ...\n",
       "36598   After   1889699  Music,beats,instrumental,right beat radio,stra...\n",
       "        After   1889700  Music,beats,instrumental,right beat radio,late...\n",
       "        After   1889701  Music,beats,instrumental,right beat radio,lofi...\n",
       "        After   1889702  Music,beats,instrumental,right beat radio,mell...\n",
       "        After   1889703  Music,beats,instrumental,right beat radio,lofi...\n",
       "\n",
       "[2069978 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map to obtain the tags of all videos for each video before and after decline\n",
    "df_tags['Tags'] = df_tags['Video'].map(lambda video: videos.loc[video, 'tags'] if video in videos.index else None)\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,21st birthday,birthday,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,OUTFIT DIARIES\\nMsRosie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,gameplay,review,guide,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,playthrough,blind play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>After</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36595</th>\n",
       "      <th>Before</th>\n",
       "      <td>Despacito accordion cover,Fonsi Despacito acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36597</th>\n",
       "      <th>After</th>\n",
       "      <td>Patriot Attitude,Plasma Art,#whenhellfreezesov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Bridgeport,Stainless Steel Placards,Roller Kit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,rhod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,lofi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61194 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined\n",
       "Decline Source                                                   \n",
       "0       After   MsRosieBea\\nMsRosieBea,21st birthday,birthday,...\n",
       "        Before  MsRosieBea\\nMsRosieBea,OUTFIT DIARIES\\nMsRosie...\n",
       "1       After   hollow,generationhollow,gameplay,review,guide,...\n",
       "        Before  hollow,generationhollow,playthrough,blind play...\n",
       "2       After                                                None\n",
       "...                                                           ...\n",
       "36595   Before  Despacito accordion cover,Fonsi Despacito acco...\n",
       "36597   After   Patriot Attitude,Plasma Art,#whenhellfreezesov...\n",
       "        Before  Bridgeport,Stainless Steel Placards,Roller Kit...\n",
       "36598   After   Music,beats,instrumental,right beat radio,rhod...\n",
       "        Before  Music,beats,instrumental,right beat radio,lofi...\n",
       "\n",
       "[61194 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get for each decline only 2 rows with the tags corresponding to the before and the after, handling NaNs and non-list values\n",
    "df_tags = df_tags.groupby(['Decline', 'Source'])['Tags'].apply(\n",
    "    lambda x: list(set([item for sublist in x.dropna() for item in (sublist if isinstance(sublist, list) else [sublist])]))\n",
    ").reset_index(name='Tags_combined')\n",
    "\n",
    "df_tags.set_index(['Decline', 'Source'], inplace=True)\n",
    "\n",
    "# Map the tags to a string, separating them by new lines\n",
    "df_tags['Tags_combined'] = df_tags['Tags_combined'].map(lambda tags: '\\n'.join(tags) if tags else None)\n",
    "\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "CASEFOLD = False\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_str(s):\n",
    "    if not isinstance(s, str) or not s.strip(): # Cases where s = None\n",
    "        return []\n",
    "    s = s.lower()\n",
    "    tokens = word_tokenize(s.lower() if CASEFOLD else s, preserve_line=True)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "df_small = df_tags.head(100)\n",
    "print(df_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/q2x3vw9j7tnghtzghrscmg9w0000gn/T/ipykernel_28800/1432068147.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['Tokens'] = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and lemmatizing tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 375.81it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing and lemmatizing tags\")\n",
    "df_small['Tokens'] = None\n",
    "for index, row in tqdm(df_small.iterrows(), total=df_small.shape[0]):\n",
    "    df_small.at[index, 'Tokens'] = preprocess_str(row['Tags_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary and corpus\n",
      "Training LDA model\n",
      "(8, '0.072*\"gun\" + 0.057*\"duty\" + 0.054*\"call\" + 0.050*\"ww2\" + 0.048*\"motion\" + 0.048*\"slow\" + 0.035*\"weapon\" + 0.034*\"battlefield\" + 0.032*\"animation\"')\n",
      "(32, '0.135*\"fortnite\" + 0.039*\"ninja\" + 0.029*\"voice\" + 0.029*\"real\" + 0.023*\"moment\" + 0.023*\"funny\" + 0.017*\"\\'s\" + 0.015*\"faze\" + 0.015*\"montage\"')\n",
      "(17, '0.000*\"wander\" + 0.000*\"corbin\" + 0.000*\"van\" + 0.000*\"kelsey\" + 0.000*\"life\" + 0.000*\"pregnancy\" + 0.000*\"house\" + 0.000*\"new\" + 0.000*\"rv\"')\n",
      "(22, '0.037*\"urdu\" + 0.025*\"opener\" + 0.025*\"youtube\" + 0.022*\"illuminati\" + 0.021*\"tv\" + 0.021*\"hindi\" + 0.020*\"time\" + 0.019*\"space\" + 0.016*\"poem\"')\n",
      "(42, '0.032*\"fortnitegod\" + 0.030*\"fortnite\" + 0.020*\"fortnitemyth\" + 0.019*\"howtofortnite\" + 0.018*\"ninjafortnite\" + 0.018*\"fortniteps4\" + 0.016*\"bestplayerinconsole\" + 0.016*\"fortnitebestplayer\" + 0.013*\"fortniteninja\"')\n",
      "(48, '0.097*\"2017\" + 0.089*\"hees\" + 0.071*\"cusub\" + 0.056*\"lafoole\" + 0.050*\"somali\" + 0.040*\"indho\" + 0.040*\"nasteexo\" + 0.036*\"niiko\" + 0.028*\"ciida\"')\n",
      "(30, '0.042*\"let\" + 0.023*\"\\'s\" + 0.020*\"play\" + 0.017*\"game\" + 0.015*\"video\" + 0.015*\"gameplay\" + 0.015*\"walkthrough\" + 0.015*\"ps2\" + 0.014*\"commentary\"')\n",
      "(35, '0.069*\"msrosiebea\" + 0.055*\"uni\" + 0.021*\"design\" + 0.011*\"year\" + 0.011*\"birthday\" + 0.011*\"tall\" + 0.011*\"england\" + 0.009*\"yasha\" + 0.009*\"cyr\"')\n",
      "(5, '0.050*\"skin\" + 0.021*\"remover\" + 0.019*\"simple\" + 0.018*\"make-up\" + 0.017*\"care\" + 0.017*\"dylangous\" + 0.015*\"cleansing\" + 0.014*\"book\" + 0.014*\"philosophy\"')\n",
      "(18, '0.018*\"alex\" + 0.016*\"three\" + 0.016*\"clare\" + 0.008*\"day\" + 0.008*\"heart\" + 0.008*\"greenmount\" + 0.000*\"fortnite\" + 0.000*\"corbin\" + 0.000*\"wander\"')\n",
      "(46, '0.104*\"teacher\" + 0.048*\"classroom\" + 0.032*\"first\" + 0.029*\"fridge\" + 0.026*\"tip\" + 0.022*\"year\" + 0.022*\"vlog\" + 0.019*\"instagram\" + 0.016*\"book\"')\n",
      "(13, '0.053*\"yasha\" + 0.039*\"daniela\" + 0.030*\"circus\" + 0.026*\"viva\" + 0.022*\"cyr\" + 0.020*\"akrosphere\" + 0.020*\"jeltuhin\" + 0.020*\"fest\" + 0.013*\"avanzini\"')\n",
      "(20, '0.000*\"teacher\" + 0.000*\"classroom\" + 0.000*\"let\" + 0.000*\"game\" + 0.000*\"interview\" + 0.000*\"dog\" + 0.000*\"video\" + 0.000*\"tip\" + 0.000*\"gaming\"')\n",
      "(45, '0.029*\"new\" + 0.029*\"york\" + 0.024*\"model\" + 0.023*\"college\" + 0.019*\"cute\" + 0.019*\"nyc\" + 0.017*\"fashion\" + 0.017*\"city\" + 0.017*\"fit\"')\n",
      "(25, '0.033*\"tip\" + 0.025*\"guide\" + 0.023*\"hollow\" + 0.023*\"generationhollow\" + 0.020*\"gameplay\" + 0.020*\"tutorial\" + 0.018*\"playthrough\" + 0.017*\"trick\" + 0.013*\"hero\"')\n",
      "(50, '0.134*\"beat\" + 0.074*\"type\" + 0.058*\"instrumental\" + 0.057*\"rap\" + 0.049*\"trap\" + 0.028*\"free\" + 0.027*\"dark\" + 0.026*\"de\" + 0.024*\"hip\"')\n",
      "(36, '0.123*\"blackpink\" + 0.085*\"du\" + 0.085*\"ddu\" + 0.045*\"블랙핑크\" + 0.045*\"reaction\" + 0.043*\"square\" + 0.028*\"shane\" + 0.028*\"kpop\" + 0.024*\"comeback\"')\n",
      "(44, '0.047*\"funny\" + 0.045*\"best\" + 0.044*\"moment\" + 0.026*\"base\" + 0.024*\"stimpee\" + 0.022*\"solo\" + 0.022*\"survival\" + 0.022*\"rust\" + 0.022*\"gameplay\"')\n",
      "(4, '0.043*\"soul\" + 0.036*\"surge\" + 0.029*\"ringed\" + 0.025*\"dark\" + 0.025*\"city\" + 0.021*\"1\" + 0.020*\"2\" + 0.019*\"blind\" + 0.018*\"speed\"')\n",
      "(9, '0.086*\"fashion\" + 0.063*\"indian\" + 0.037*\"outfit\" + 0.034*\"summer\" + 0.029*\"lookbook\" + 0.023*\"style\" + 0.023*\"festive\" + 0.022*\"college\" + 0.021*\"grwm\"')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,21st birthday,birthday,...</td>\n",
       "      <td>[msrosiebea, msrosiebea,21st, birthday, birthd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,OUTFIT DIARIES\\nMsRosie...</td>\n",
       "      <td>[msrosiebea, msrosiebea, outfit, diary, msrosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,gameplay,review,guide,...</td>\n",
       "      <td>[hollow, generationhollow, gameplay, review, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,playthrough,blind play...</td>\n",
       "      <td>[hollow, generationhollow, playthrough, blind,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>After</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">55</th>\n",
       "      <th>After</th>\n",
       "      <td>boris Johnson,Brexit,new pm boris Johnson,Brex...</td>\n",
       "      <td>[boris, johnson, brexit, new, pm, boris, johns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>james o'brien,james o'brien brexit,brexit disa...</td>\n",
       "      <td>[james, o'brien, james, o'brien, brexit, brexi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">57</th>\n",
       "      <th>After</th>\n",
       "      <td>suicide boys type beat,ghostemane type beat,xx...</td>\n",
       "      <td>[suicide, boy, type, beat, ghostemane, type, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>beat,jazz,sax,saxofon,rhodes,chill,dark,experi...</td>\n",
       "      <td>[beat, jazz, sax, saxofon, rhodes, chill, dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <th>After</th>\n",
       "      <td>plan with me,erin condren,life planner,2019,20...</td>\n",
       "      <td>[plan, erin, condren, life, planner,2019,2020,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined  \\\n",
       "Decline Source                                                      \n",
       "0       After   MsRosieBea\\nMsRosieBea,21st birthday,birthday,...   \n",
       "        Before  MsRosieBea\\nMsRosieBea,OUTFIT DIARIES\\nMsRosie...   \n",
       "1       After   hollow,generationhollow,gameplay,review,guide,...   \n",
       "        Before  hollow,generationhollow,playthrough,blind play...   \n",
       "2       After                                                None   \n",
       "...                                                           ...   \n",
       "55      After   boris Johnson,Brexit,new pm boris Johnson,Brex...   \n",
       "        Before  james o'brien,james o'brien brexit,brexit disa...   \n",
       "57      After   suicide boys type beat,ghostemane type beat,xx...   \n",
       "        Before  beat,jazz,sax,saxofon,rhodes,chill,dark,experi...   \n",
       "58      After   plan with me,erin condren,life planner,2019,20...   \n",
       "\n",
       "                                                           Tokens  \n",
       "Decline Source                                                     \n",
       "0       After   [msrosiebea, msrosiebea,21st, birthday, birthd...  \n",
       "        Before  [msrosiebea, msrosiebea, outfit, diary, msrosi...  \n",
       "1       After   [hollow, generationhollow, gameplay, review, g...  \n",
       "        Before  [hollow, generationhollow, playthrough, blind,...  \n",
       "2       After                                                  []  \n",
       "...                                                           ...  \n",
       "55      After   [boris, johnson, brexit, new, pm, boris, johns...  \n",
       "        Before  [james, o'brien, james, o'brien, brexit, brexi...  \n",
       "57      After   [suicide, boy, type, beat, ghostemane, type, b...  \n",
       "        Before  [beat, jazz, sax, saxofon, rhodes, chill, dark...  \n",
       "58      After   [plan, erin, condren, life, planner,2019,2020,...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary and a corpus for the LDA model\n",
    "print(\"Creating dictionary and corpus\")\n",
    "dictionary = corpora.Dictionary(df_small['Tokens'])\n",
    "corpus = [dictionary.doc2bow(token_list) for token_list in df_small['Tokens']]\n",
    "\n",
    "print(\"Training LDA model\")\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=55, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = lda.print_topics(num_words=9)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning topics to each document\n",
      "                                                    Tags_combined  \\\n",
      "Decline Source                                                      \n",
      "0       After   MsRosieBea\\nMsRosieBea,21st birthday,birthday,...   \n",
      "        Before  MsRosieBea\\nMsRosieBea,OUTFIT DIARIES\\nMsRosie...   \n",
      "1       After   hollow,generationhollow,gameplay,review,guide,...   \n",
      "        Before  hollow,generationhollow,playthrough,blind play...   \n",
      "2       After                                                None   \n",
      "        Before                                               None   \n",
      "3       After   pubg,killstreak,player unknowns battleground,b...   \n",
      "        Before  Rust,wipe,wipe day,horrible,a horrible wipe,lu...   \n",
      "4       After   breyerfest,BreyerFest 2019,2019,2018,30th anni...   \n",
      "        Before  Breyer,BreyerFest,CollectA,American Alligator,...   \n",
      "5       After   Triple Entray,Phora,Drake,Eminem,Justin Bieber...   \n",
      "        Before  Triple Entray,Hip hop,Phora,Eminem,King Lil G,...   \n",
      "7       After   Yasha,Yasha Jeltuhin,Cyr,Cyr Wheel,Circus,Akro...   \n",
      "        Before  Yasha,Yasha Jeltuhin,Akrosphere,Circus,Jen Mac...   \n",
      "8       After   free type beats,free untagged beats,playboi ca...   \n",
      "        Before  impulsebeats,yung impulse,impulse beats,impuls...   \n",
      "9       After                                                None   \n",
      "        Before                                               None   \n",
      "10      After   pumpkin,patch,best pumpkin patch,baby,toddler,...   \n",
      "        Before  Steps To Wander,StepsToWander,TheWanderFamily,...   \n",
      "\n",
      "                                                           Tokens  \\\n",
      "Decline Source                                                      \n",
      "0       After   [msrosiebea, msrosiebea,21st, birthday, birthd...   \n",
      "        Before  [msrosiebea, msrosiebea, outfit, diary, msrosi...   \n",
      "1       After   [hollow, generationhollow, gameplay, review, g...   \n",
      "        Before  [hollow, generationhollow, playthrough, blind,...   \n",
      "2       After                                                  []   \n",
      "        Before                                                 []   \n",
      "3       After   [pubg, killstreak, player, unknown, battlegrou...   \n",
      "        Before  [rust, wipe, wipe, day, horrible, horrible, wi...   \n",
      "4       After   [breyerfest, breyerfest, 2019,2019,2018,30th, ...   \n",
      "        Before  [breyer, breyerfest, collecta, american, allig...   \n",
      "5       After   [triple, entray, phora, drake, eminem, justin,...   \n",
      "        Before  [triple, entray, hip, hop, phora, eminem, king...   \n",
      "7       After   [yasha, yasha, jeltuhin, cyr, cyr, wheel, circ...   \n",
      "        Before  [yasha, yasha, jeltuhin, akrosphere, circus, j...   \n",
      "8       After   [free, type, beat, free, untagged, beat, playb...   \n",
      "        Before  [impulsebeats, yung, impulse, impulse, beat, i...   \n",
      "9       After                                                  []   \n",
      "        Before                                                 []   \n",
      "10      After   [pumpkin, patch, best, pumpkin, patch, baby, t...   \n",
      "        Before  [step, wander, stepstowander, thewanderfamily,...   \n",
      "\n",
      "                Dominant_Topic  Topic_Probability  \n",
      "Decline Source                                     \n",
      "0       After             35.0           0.960727  \n",
      "        Before             1.0           0.456776  \n",
      "1       After             25.0           0.712958  \n",
      "        Before            25.0           0.997674  \n",
      "2       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "3       After             31.0           0.681234  \n",
      "        Before            44.0           0.999111  \n",
      "4       After             49.0           0.600099  \n",
      "        Before            49.0           0.952966  \n",
      "5       After             45.0           0.602180  \n",
      "        Before            45.0           0.986732  \n",
      "7       After             13.0           0.968328  \n",
      "        Before            13.0           0.734458  \n",
      "8       After             54.0           0.836099  \n",
      "        Before            38.0           0.964935  \n",
      "9       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "10      After             26.0           0.999282  \n",
      "        Before            26.0           0.999813  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/q2x3vw9j7tnghtzghrscmg9w0000gn/T/ipykernel_28800/3727712663.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['Dominant_Topic'], df_small['Topic_Probability'] = zip(\n",
      "/var/folders/82/q2x3vw9j7tnghtzghrscmg9w0000gn/T/ipykernel_28800/3727712663.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['Dominant_Topic'], df_small['Topic_Probability'] = zip(\n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning topics to each document\")\n",
    "\n",
    "# Assign the dominant topic to each document\n",
    "def assign_dominant_topic(tokens, lda_model, dictionary):\n",
    "    if not tokens or not isinstance(tokens, list):  # Handle empty or invalid tokens\n",
    "        return None, None\n",
    "    bow = dictionary.doc2bow(tokens)  # Convert tokens to bag-of-words format\n",
    "    topic_probs = lda_model.get_document_topics(bow)  # Get topic distribution\n",
    "    if topic_probs:\n",
    "        dominant_topic, prob = max(topic_probs, key=lambda x: x[1])  # Most probable topic\n",
    "        return dominant_topic, prob\n",
    "    return None, None\n",
    "\n",
    "df_small['Dominant_Topic'], df_small['Topic_Probability'] = zip(\n",
    "    *df_small['Tokens'].apply(lambda tokens: assign_dominant_topic(tokens, lda, dictionary))\n",
    ")\n",
    "\n",
    "print(df_small.head(20))\n",
    "df_small.to_csv('data/df_small_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create two columns [Topic_change] and [Tokens_change] to determine if there is a difference between the tags before and after a decline. A change in tokens is used for granular analysis while a change is topics is more appropriate for detecting higher-level patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>msrosiebea msrosiebea,21st birthday birthday r...</td>\n",
       "      <td>msrosiebea msrosiebea outfit diary msrosiebea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>hollow generationhollow gameplay review guide ...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>pubg killstreak player unknown battleground ba...</td>\n",
       "      <td>rust wipe wipe day horrible horrible wipe luck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>breyerfest breyerfest 2019,2019,2018,30th anni...</td>\n",
       "      <td>breyer breyerfest collecta american alligator ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>triple entray phora drake eminem justin bieber...</td>\n",
       "      <td>triple entray hip hop phora eminem king lil g ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 35.0    1.0   \n",
       "1                 25.0   25.0   \n",
       "3                 31.0   44.0   \n",
       "4                 49.0   49.0   \n",
       "5                 45.0   45.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        msrosiebea msrosiebea,21st birthday birthday r...   \n",
       "1        hollow generationhollow gameplay review guide ...   \n",
       "3        pubg killstreak player unknown battleground ba...   \n",
       "4        breyerfest breyerfest 2019,2019,2018,30th anni...   \n",
       "5        triple entray phora drake eminem justin bieber...   \n",
       "\n",
       "                                                            \n",
       "Source                                              Before  \n",
       "Decline                                                     \n",
       "0        msrosiebea msrosiebea outfit diary msrosiebea ...  \n",
       "1        hollow generationhollow playthrough blind play...  \n",
       "3        rust wipe wipe day horrible horrible wipe luck...  \n",
       "4        breyer breyerfest collecta american alligator ...  \n",
       "5        triple entray hip hop phora eminem king lil g ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df_small.dropna(subset=['Tokens', 'Dominant_Topic'])\n",
    "\n",
    "# Pivot the dataset, keeping 'Dominant_topic' in a separate column\n",
    "df_pivot = df_small.pivot_table(\n",
    "    index='Decline',  # The index will be based on the 'Decline'\n",
    "    columns='Source',  # We are splitting by 'Source' (Before and After)\n",
    "    values=['Tokens', 'Dominant_Topic'],  # We want both Tokens and Dominant_topic in the pivoted table\n",
    "    aggfunc={\n",
    "        'Tokens': lambda x: ' '.join([item for sublist in x for item in sublist]),  # Flatten and join the tokens\n",
    "        'Dominant_Topic': lambda x: x.mode()[0]  # Get the most frequent dominant topic (mode)\n",
    "    }\n",
    ")\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "      <th>Token_Change</th>\n",
       "      <th>Topic_Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>msrosiebea msrosiebea,21st birthday birthday r...</td>\n",
       "      <td>msrosiebea msrosiebea outfit diary msrosiebea ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>hollow generationhollow gameplay review guide ...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>pubg killstreak player unknown battleground ba...</td>\n",
       "      <td>rust wipe wipe day horrible horrible wipe luck...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>breyerfest breyerfest 2019,2019,2018,30th anni...</td>\n",
       "      <td>breyer breyerfest collecta american alligator ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>triple entray phora drake eminem justin bieber...</td>\n",
       "      <td>triple entray hip hop phora eminem king lil g ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 35.0    1.0   \n",
       "1                 25.0   25.0   \n",
       "3                 31.0   44.0   \n",
       "4                 49.0   49.0   \n",
       "5                 45.0   45.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        msrosiebea msrosiebea,21st birthday birthday r...   \n",
       "1        hollow generationhollow gameplay review guide ...   \n",
       "3        pubg killstreak player unknown battleground ba...   \n",
       "4        breyerfest breyerfest 2019,2019,2018,30th anni...   \n",
       "5        triple entray phora drake eminem justin bieber...   \n",
       "\n",
       "                                                           Token_Change  \\\n",
       "Source                                              Before                \n",
       "Decline                                                                   \n",
       "0        msrosiebea msrosiebea outfit diary msrosiebea ...        False   \n",
       "1        hollow generationhollow playthrough blind play...        False   \n",
       "3        rust wipe wipe day horrible horrible wipe luck...        False   \n",
       "4        breyer breyerfest collecta american alligator ...        False   \n",
       "5        triple entray hip hop phora eminem king lil g ...        False   \n",
       "\n",
       "        Topic_Change  \n",
       "Source                \n",
       "Decline               \n",
       "0               True  \n",
       "1              False  \n",
       "3               True  \n",
       "4              False  \n",
       "5              False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_change(tokens_before, tokens_after):\n",
    "    # Ensure tokens are lists and not NaN or float\n",
    "    if not isinstance(tokens_before, list):\n",
    "        tokens_before = []\n",
    "    if not isinstance(tokens_after, list):\n",
    "        tokens_after = []\n",
    "        \n",
    "    # Compare sets of tokens\n",
    "    set_before = set(tokens_before)\n",
    "    set_after = set(tokens_after)\n",
    "    return set_before != set_after  # Change if the sets are not identical\n",
    "\n",
    "# Apply the token change function to compare the tokens before and after for each decline\n",
    "df_pivot['Token_Change'] = df_pivot.apply(\n",
    "    lambda row: token_change(row[('Tokens', 'Before')], row[('Tokens', 'After')]), axis=1)\n",
    "\n",
    "# Assuming 'Dominant_topic' columns are available for 'Before' and 'After'\n",
    "df_pivot['Topic_Change'] = df_pivot.apply(\n",
    "    lambda row: row[('Dominant_Topic', 'Before')] != row[('Dominant_Topic', 'After')], axis=1)\n",
    "\n",
    "# Verify the results\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.6784999505432454\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=df_small['Tokens'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}') # 0.7475 with 55 topics, numwords = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and lemmatizing tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61194/61194 [03:29<00:00, 292.74it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing and lemmatizing tags\")\n",
    "df_tags['Tokens'] = None\n",
    "for index, row in tqdm(df_tags.iterrows(), total=df_tags.shape[0]):\n",
    "    df_tags.at[index, 'Tokens'] = preprocess_str(row['Tags_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary and corpus\n",
      "Training LDA model\n",
      "(0, '0.023*\"car\" + 0.013*\"golf\" + 0.010*\"train\" + 0.009*\"asmr\" + 0.009*\"travel\" + 0.007*\"crash\" + 0.006*\"racing\" + 0.006*\"dubai\" + 0.006*\"fishing\" + 0.006*\"bike\" + 0.006*\"race\" + 0.006*\"road\" + 0.006*\"park\" + 0.005*\"street\" + 0.005*\"tour\"')\n",
      "(1, '0.043*\"gta\" + 0.041*\"v\" + 0.039*\"movie\" + 0.038*\"5\" + 0.026*\"online\" + 0.022*\"season\" + 0.020*\"trailer\" + 0.015*\"review\" + 0.015*\"comic\" + 0.014*\"4\" + 0.014*\"episode\" + 0.012*\"film\" + 0.011*\"6\" + 0.010*\"marvel\" + 0.010*\"money\"')\n",
      "(2, '0.076*\"news\" + 0.031*\"2019\" + 0.030*\"video\" + 0.027*\"cricket\" + 0.023*\"hindi\" + 0.022*\"latest\" + 0.017*\"song\" + 0.017*\"2018\" + 0.016*\"pgt\" + 0.016*\"indian\" + 0.016*\"india\" + 0.014*\"new\" + 0.014*\"pakistan\" + 0.014*\"live\" + 0.012*\"tv\"')\n",
      "(3, '0.063*\"pokemon\" + 0.021*\"android\" + 0.018*\"free\" + 0.017*\"go\" + 0.016*\"best\" + 0.013*\"iphone\" + 0.013*\"review\" + 0.011*\"card\" + 0.011*\"new\" + 0.010*\"moon\" + 0.010*\"sun\" + 0.010*\"io\" + 0.010*\"shiny\" + 0.008*\"pro\" + 0.008*\"hack\"')\n",
      "(4, '0.020*\"news\" + 0.013*\"trump\" + 0.009*\"world\" + 0.007*\"time\" + 0.007*\"show\" + 0.006*\"politics\" + 0.006*\"state\" + 0.006*\"u\" + 0.006*\"medium\" + 0.005*\"donald\" + 0.005*\"interview\" + 0.005*\"live\" + 0.005*\"business\" + 0.005*\"woman\" + 0.005*\"entertainment\"')\n",
      "(5, '0.110*\"fortnite\" + 0.029*\"battle\" + 0.025*\"new\" + 0.023*\"moment\" + 0.023*\"funny\" + 0.021*\"royale\" + 0.017*\"gameplay\" + 0.017*\"best\" + 0.015*\"pubg\" + 0.013*\"skin\" + 0.013*\"season\" + 0.011*\"mobile\" + 0.011*\"update\" + 0.010*\"rocket\" + 0.010*\"battlefield\"')\n",
      "(6, '0.025*\"ark\" + 0.016*\"tarot\" + 0.014*\"reading\" + 0.014*\"rust\" + 0.013*\"2017\" + 0.012*\"survival\" + 0.011*\"fallout\" + 0.011*\"hockey\" + 0.011*\"angel\" + 0.011*\"love\" + 0.009*\"unturned\" + 0.009*\"2018\" + 0.008*\"space\" + 0.008*\"planet\" + 0.008*\"f1\"')\n",
      "(7, '0.060*\"beat\" + 0.043*\"type\" + 0.022*\"sport\" + 0.022*\"basketball\" + 0.022*\"free\" + 0.019*\"highlight\" + 0.017*\"minor\" + 0.015*\"2018\" + 0.015*\"baseball\" + 0.012*\"nfl\" + 0.011*\"nba\" + 0.010*\"tmz\" + 0.009*\"raven\" + 0.009*\"pick\" + 0.009*\"lil\"')\n",
      "(8, '0.125*\"2\" + 0.061*\"destiny\" + 0.037*\"design\" + 0.018*\"art\" + 0.018*\"red\" + 0.018*\"new\" + 0.017*\"division\" + 0.014*\"simple\" + 0.014*\"dead\" + 0.013*\"dot\" + 0.013*\"easy\" + 0.013*\"guide\" + 0.011*\"redemption\" + 0.010*\"anthem\" + 0.009*\"gameplay\"')\n",
      "(9, '0.094*\"wwe\" + 0.025*\"v\" + 0.023*\"sport\" + 0.015*\"boxing\" + 0.015*\"raw\" + 0.014*\"fight\" + 0.013*\"ufc\" + 0.011*\"wrestling\" + 0.009*\"match\" + 0.009*\"fury\" + 0.009*\"championship\" + 0.008*\"john\" + 0.008*\"mma\" + 0.008*\"garcia\" + 0.008*\"world\"')\n",
      "(10, '0.060*\"black\" + 0.045*\"call\" + 0.042*\"ops\" + 0.041*\"zombie\" + 0.038*\"duty\" + 0.034*\"cod\" + 0.030*\"3\" + 0.028*\"ww2\" + 0.023*\"4\" + 0.018*\"warfare\" + 0.018*\"bo4\" + 0.016*\"faze\" + 0.015*\"dead\" + 0.014*\"glitch\" + 0.014*\"gameplay\"')\n",
      "(11, '0.077*\"minecraft\" + 0.062*\"roblox\" + 0.036*\"mod\" + 0.020*\"simulator\" + 0.016*\"wow\" + 0.016*\"friendly\" + 0.015*\"pvp\" + 0.015*\"raid\" + 0.013*\"game\" + 0.012*\"play\" + 0.011*\"server\" + 0.011*\"warcraft\" + 0.010*\"faction\" + 0.010*\"trolling\" + 0.009*\"world\"')\n",
      "(12, '0.057*\"game\" + 0.031*\"gameplay\" + 0.020*\"play\" + 0.018*\"war\" + 0.017*\"let\" + 0.017*\"2\" + 0.017*\"\\'s\" + 0.015*\"star\" + 0.013*\"nintendo\" + 0.011*\"gaming\" + 0.011*\"walkthrough\" + 0.010*\"switch\" + 0.009*\"super\" + 0.009*\"smash\" + 0.009*\"part\"')\n",
      "(13, '0.042*\"clash\" + 0.021*\"deck\" + 0.020*\"royale\" + 0.019*\"workout\" + 0.019*\"tennis\" + 0.016*\"best\" + 0.015*\"clan\" + 0.013*\"open\" + 0.013*\"fitness\" + 0.013*\"arena\" + 0.012*\"magic\" + 0.012*\"weight\" + 0.012*\"de\" + 0.009*\"paladin\" + 0.008*\"roland\"')\n",
      "(14, '0.047*\"fifa\" + 0.037*\"18\" + 0.034*\"19\" + 0.031*\"nba\" + 0.030*\"madden\" + 0.026*\"team\" + 0.020*\"cup\" + 0.020*\"17\" + 0.019*\"pack\" + 0.019*\"league\" + 0.014*\"football\" + 0.014*\"ultimate\" + 0.012*\"best\" + 0.011*\"gameplay\" + 0.011*\"career\"')\n",
      "(15, '0.034*\"makeup\" + 0.019*\"haul\" + 0.015*\"hair\" + 0.014*\"tutorial\" + 0.014*\"beauty\" + 0.012*\"fashion\" + 0.011*\"diy\" + 0.009*\"recipe\" + 0.008*\"review\" + 0.008*\"style\" + 0.007*\"home\" + 0.007*\"day\" + 0.007*\"make\" + 0.007*\"idea\" + 0.007*\"vegan\"')\n",
      "(16, '0.042*\"music\" + 0.021*\"reaction\" + 0.016*\"dance\" + 0.016*\"song\" + 0.011*\"trap\" + 0.010*\"video\" + 0.010*\"new\" + 0.010*\"cover\" + 0.009*\"talent\" + 0.009*\"meme\" + 0.008*\"remix\" + 0.008*\"rap\" + 0.007*\"pop\" + 0.007*\"house\" + 0.007*\"live\"')\n",
      "(17, '0.026*\"vlog\" + 0.024*\"family\" + 0.023*\"funny\" + 0.014*\"life\" + 0.013*\"video\" + 0.013*\"prank\" + 0.012*\"vlogs\" + 0.010*\"challenge\" + 0.010*\"daily\" + 0.010*\"youtube\" + 0.010*\"comedy\" + 0.009*\"baby\" + 0.008*\"girl\" + 0.007*\"vlogger\" + 0.006*\"mom\"')\n",
      "(18, '0.047*\"league\" + 0.035*\"dota\" + 0.022*\"v\" + 0.022*\"overwatch\" + 0.020*\"legend\" + 0.020*\"csgo\" + 0.017*\"highlight\" + 0.016*\"bitcoin\" + 0.015*\"lol\" + 0.013*\"pro\" + 0.012*\"c\" + 0.010*\"best\" + 0.009*\"cryptocurrency\" + 0.009*\"top\" + 0.008*\"gaming\"')\n",
      "(19, '0.048*\"kid\" + 0.032*\"toy\" + 0.028*\"video\" + 0.014*\"baby\" + 0.013*\"disney\" + 0.013*\"fun\" + 0.012*\"animal\" + 0.012*\"game\" + 0.012*\"slime\" + 0.012*\"color\" + 0.011*\"learn\" + 0.011*\"cat\" + 0.010*\"play\" + 0.010*\"funny\" + 0.010*\"child\"')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary and a corpus for the LDA model\n",
    "print(\"Creating dictionary and corpus\")\n",
    "dictionary = corpora.Dictionary(df_tags['Tokens'])\n",
    "corpus = [dictionary.doc2bow(token_list) for token_list in df_tags['Tokens']]\n",
    "\n",
    "print(\"Training LDA model\")\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=20, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = lda.print_topics(num_words=15)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics saved to lda_topics.csv\n"
     ]
    }
   ],
   "source": [
    "topics = lda.print_topics(num_words=15)\n",
    "\n",
    "# Create a DataFrame from the topics\n",
    "topics_data = []\n",
    "for topic_id, topic in topics:\n",
    "    topics_data.append({\"Topic\": topic_id, \"Words\": topic})\n",
    "\n",
    "topics_df = pd.DataFrame(topics_data)\n",
    "\n",
    "topics_df.to_csv(\"data/lda_topics.csv\", index=False)\n",
    "print(\"Topics saved to lda_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning topics to each document\n",
      "                                                    Tags_combined  \\\n",
      "Decline Source                                                      \n",
      "0       After   MsRosieBea\\nMsRosieBea,21st birthday,birthday,...   \n",
      "        Before  MsRosieBea\\nMsRosieBea,OUTFIT DIARIES\\nMsRosie...   \n",
      "1       After   hollow,generationhollow,gameplay,review,guide,...   \n",
      "        Before  hollow,generationhollow,playthrough,blind play...   \n",
      "2       After                                                None   \n",
      "        Before                                               None   \n",
      "3       After   pubg,killstreak,player unknowns battleground,b...   \n",
      "        Before  Rust,wipe,wipe day,horrible,a horrible wipe,lu...   \n",
      "4       After   breyerfest,BreyerFest 2019,2019,2018,30th anni...   \n",
      "        Before  Breyer,BreyerFest,CollectA,American Alligator,...   \n",
      "5       After   Triple Entray,Phora,Drake,Eminem,Justin Bieber...   \n",
      "        Before  Triple Entray,Hip hop,Phora,Eminem,King Lil G,...   \n",
      "7       After   Yasha,Yasha Jeltuhin,Cyr,Cyr Wheel,Circus,Akro...   \n",
      "        Before  Yasha,Yasha Jeltuhin,Akrosphere,Circus,Jen Mac...   \n",
      "8       After   free type beats,free untagged beats,playboi ca...   \n",
      "        Before  impulsebeats,yung impulse,impulse beats,impuls...   \n",
      "9       After                                                None   \n",
      "        Before                                               None   \n",
      "10      After   pumpkin,patch,best pumpkin patch,baby,toddler,...   \n",
      "        Before  Steps To Wander,StepsToWander,TheWanderFamily,...   \n",
      "\n",
      "                                                           Tokens  \\\n",
      "Decline Source                                                      \n",
      "0       After   [msrosiebea, msrosiebea,21st, birthday, birthd...   \n",
      "        Before  [msrosiebea, msrosiebea, outfit, diary, msrosi...   \n",
      "1       After   [hollow, generationhollow, gameplay, review, g...   \n",
      "        Before  [hollow, generationhollow, playthrough, blind,...   \n",
      "2       After                                                  []   \n",
      "        Before                                                 []   \n",
      "3       After   [pubg, killstreak, player, unknown, battlegrou...   \n",
      "        Before  [rust, wipe, wipe, day, horrible, horrible, wi...   \n",
      "4       After   [breyerfest, breyerfest, 2019,2019,2018,30th, ...   \n",
      "        Before  [breyer, breyerfest, collecta, american, allig...   \n",
      "5       After   [triple, entray, phora, drake, eminem, justin,...   \n",
      "        Before  [triple, entray, hip, hop, phora, eminem, king...   \n",
      "7       After   [yasha, yasha, jeltuhin, cyr, cyr, wheel, circ...   \n",
      "        Before  [yasha, yasha, jeltuhin, akrosphere, circus, j...   \n",
      "8       After   [free, type, beat, free, untagged, beat, playb...   \n",
      "        Before  [impulsebeats, yung, impulse, impulse, beat, i...   \n",
      "9       After                                                  []   \n",
      "        Before                                                 []   \n",
      "10      After   [pumpkin, patch, best, pumpkin, patch, baby, t...   \n",
      "        Before  [step, wander, stepstowander, thewanderfamily,...   \n",
      "\n",
      "                Dominant_Topic  Topic_Probability  \n",
      "Decline Source                                     \n",
      "0       After             15.0           0.952471  \n",
      "        Before            15.0           0.884730  \n",
      "1       After             12.0           0.482953  \n",
      "        Before            12.0           0.356323  \n",
      "2       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "3       After              5.0           0.476864  \n",
      "        Before             5.0           0.450269  \n",
      "4       After             19.0           0.516892  \n",
      "        Before            19.0           0.515295  \n",
      "5       After              7.0           0.341137  \n",
      "        Before             7.0           0.580626  \n",
      "7       After             16.0           0.845700  \n",
      "        Before             0.0           0.610354  \n",
      "8       After              7.0           0.709697  \n",
      "        Before             7.0           0.817446  \n",
      "9       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "10      After             17.0           0.682837  \n",
      "        Before            17.0           0.609191  \n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning topics to each document\")\n",
    "\n",
    "def assign_dominant_topic(tokens, lda_model, dictionary):\n",
    "    if not tokens or not isinstance(tokens, list):  # Handle empty or invalid tokens\n",
    "        return None, None\n",
    "    bow = dictionary.doc2bow(tokens)  # Convert tokens to bag-of-words format\n",
    "    topic_probs = lda_model.get_document_topics(bow)  # Get topic distribution\n",
    "    if topic_probs:\n",
    "        dominant_topic, prob = max(topic_probs, key=lambda x: x[1])  # Most probable topic\n",
    "        return dominant_topic, prob\n",
    "    return None, None\n",
    "\n",
    "df_tags['Dominant_Topic'], df_tags['Topic_Probability'] = zip(\n",
    "    *df_tags['Tokens'].apply(lambda tokens: assign_dominant_topic(tokens, lda, dictionary))\n",
    ")\n",
    "\n",
    "print(df_tags.head(20))\n",
    "df_tags.to_csv('data/df_small_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>msrosiebea msrosiebea,21st birthday birthday r...</td>\n",
       "      <td>msrosiebea msrosiebea outfit diary msrosiebea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>hollow generationhollow gameplay review guide ...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pubg killstreak player unknown battleground ba...</td>\n",
       "      <td>rust wipe wipe day horrible horrible wipe luck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>breyerfest breyerfest 2019,2019,2018,30th anni...</td>\n",
       "      <td>breyer breyerfest collecta american alligator ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>triple entray phora drake eminem justin bieber...</td>\n",
       "      <td>triple entray hip hop phora eminem king lil g ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yasha yasha jeltuhin cyr cyr wheel circus akro...</td>\n",
       "      <td>yasha yasha jeltuhin akrosphere circus jen mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>free type beat free untagged beat playboi cart...</td>\n",
       "      <td>impulsebeats yung impulse impulse beat impulse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>pumpkin patch best pumpkin patch baby toddler ...</td>\n",
       "      <td>step wander stepstowander thewanderfamily wand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>pharmit pharmit24 malaysia awesome gamer youtu...</td>\n",
       "      <td>pharmit pharmit24 malaysia awesome gamer youtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>twintalksballet twin twin talk talk ballet bal...</td>\n",
       "      <td>twintalksballet twin talk ballet ballerina dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>style diy hairstyle hair natural hair fashion ...</td>\n",
       "      <td>style diy hairstyle hair natural hair fashion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>hit best alphaville pop,80s art jjmacedo braga...</td>\n",
       "      <td>baladas ballad pop rock seal art jjmacedo stin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hero strike moba,3v3 game mobile brawl shooting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>simple skin care philippine simple skin care s...</td>\n",
       "      <td>simple sensitive skin facial cleansing wipe cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>kawaii mstrinity143 japan japanese candy kit s...</td>\n",
       "      <td>kawaii mstrinity143 japan japanese candy kit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>enduro world championship ewc wec endurogp end...</td>\n",
       "      <td>enduro world championship ewc wec ktm husqvarn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>teacher documentary first year teacher first y...</td>\n",
       "      <td>teacher interview teacher interview tip interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alex clare three day greenmount alex clare thr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>humanism v robot ai transhumanism steve fuller...</td>\n",
       "      <td>aging vitality rudi westendorp growing old fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ootd ootw outfit outfit ideas,2017 lookbook wi...</td>\n",
       "      <td>wrap choker choker tattoo choker chokerchoker ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 15.0   15.0   \n",
       "1                 12.0   12.0   \n",
       "3                  5.0    5.0   \n",
       "4                 19.0   19.0   \n",
       "5                  7.0    7.0   \n",
       "7                 16.0    0.0   \n",
       "8                  7.0    7.0   \n",
       "10                17.0   17.0   \n",
       "11                12.0   12.0   \n",
       "12                17.0   17.0   \n",
       "13                15.0   15.0   \n",
       "14                16.0   16.0   \n",
       "15                 NaN    5.0   \n",
       "16                15.0   15.0   \n",
       "17                19.0   19.0   \n",
       "18                 9.0    9.0   \n",
       "19                17.0   17.0   \n",
       "20                 4.0    NaN   \n",
       "21                 4.0   15.0   \n",
       "22                15.0   15.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        msrosiebea msrosiebea,21st birthday birthday r...   \n",
       "1        hollow generationhollow gameplay review guide ...   \n",
       "3        pubg killstreak player unknown battleground ba...   \n",
       "4        breyerfest breyerfest 2019,2019,2018,30th anni...   \n",
       "5        triple entray phora drake eminem justin bieber...   \n",
       "7        yasha yasha jeltuhin cyr cyr wheel circus akro...   \n",
       "8        free type beat free untagged beat playboi cart...   \n",
       "10       pumpkin patch best pumpkin patch baby toddler ...   \n",
       "11       pharmit pharmit24 malaysia awesome gamer youtu...   \n",
       "12       twintalksballet twin twin talk talk ballet bal...   \n",
       "13       style diy hairstyle hair natural hair fashion ...   \n",
       "14       hit best alphaville pop,80s art jjmacedo braga...   \n",
       "15                                                     NaN   \n",
       "16       simple skin care philippine simple skin care s...   \n",
       "17       kawaii mstrinity143 japan japanese candy kit s...   \n",
       "18       enduro world championship ewc wec endurogp end...   \n",
       "19       teacher documentary first year teacher first y...   \n",
       "20       alex clare three day greenmount alex clare thr...   \n",
       "21       humanism v robot ai transhumanism steve fuller...   \n",
       "22       ootd ootw outfit outfit ideas,2017 lookbook wi...   \n",
       "\n",
       "                                                            \n",
       "Source                                              Before  \n",
       "Decline                                                     \n",
       "0        msrosiebea msrosiebea outfit diary msrosiebea ...  \n",
       "1        hollow generationhollow playthrough blind play...  \n",
       "3        rust wipe wipe day horrible horrible wipe luck...  \n",
       "4        breyer breyerfest collecta american alligator ...  \n",
       "5        triple entray hip hop phora eminem king lil g ...  \n",
       "7        yasha yasha jeltuhin akrosphere circus jen mac...  \n",
       "8        impulsebeats yung impulse impulse beat impulse...  \n",
       "10       step wander stepstowander thewanderfamily wand...  \n",
       "11       pharmit pharmit24 malaysia awesome gamer youtu...  \n",
       "12       twintalksballet twin talk ballet ballerina dan...  \n",
       "13       style diy hairstyle hair natural hair fashion ...  \n",
       "14       baladas ballad pop rock seal art jjmacedo stin...  \n",
       "15         hero strike moba,3v3 game mobile brawl shooting  \n",
       "16       simple sensitive skin facial cleansing wipe cl...  \n",
       "17       kawaii mstrinity143 japan japanese candy kit s...  \n",
       "18       enduro world championship ewc wec ktm husqvarn...  \n",
       "19       teacher interview teacher interview tip interv...  \n",
       "20                                                     NaN  \n",
       "21       aging vitality rudi westendorp growing old fre...  \n",
       "22       wrap choker choker tattoo choker chokerchoker ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags = df_tags.dropna(subset=['Tokens', 'Dominant_Topic'])\n",
    "\n",
    "# Pivot the dataset\n",
    "df_pivot = df_tags.pivot_table(\n",
    "    index='Decline',  \n",
    "    columns='Source',  \n",
    "    values=['Tokens', 'Dominant_Topic'],  \n",
    "    aggfunc={\n",
    "        'Tokens': lambda x: ' '.join([item for sublist in x for item in sublist]),  # Flatten and join the tokens\n",
    "        'Dominant_Topic': lambda x: x.mode()[0]  # Get the most frequent dominant topic\n",
    "    }\n",
    ")\n",
    "\n",
    "df_pivot.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "      <th>Token_Change</th>\n",
       "      <th>Topic_Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>msrosiebea msrosiebea,21st birthday birthday r...</td>\n",
       "      <td>msrosiebea msrosiebea outfit diary msrosiebea ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>hollow generationhollow gameplay review guide ...</td>\n",
       "      <td>hollow generationhollow playthrough blind play...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pubg killstreak player unknown battleground ba...</td>\n",
       "      <td>rust wipe wipe day horrible horrible wipe luck...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>breyerfest breyerfest 2019,2019,2018,30th anni...</td>\n",
       "      <td>breyer breyerfest collecta american alligator ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>triple entray phora drake eminem justin bieber...</td>\n",
       "      <td>triple entray hip hop phora eminem king lil g ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 15.0   15.0   \n",
       "1                 12.0   12.0   \n",
       "3                  5.0    5.0   \n",
       "4                 19.0   19.0   \n",
       "5                  7.0    7.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        msrosiebea msrosiebea,21st birthday birthday r...   \n",
       "1        hollow generationhollow gameplay review guide ...   \n",
       "3        pubg killstreak player unknown battleground ba...   \n",
       "4        breyerfest breyerfest 2019,2019,2018,30th anni...   \n",
       "5        triple entray phora drake eminem justin bieber...   \n",
       "\n",
       "                                                           Token_Change  \\\n",
       "Source                                              Before                \n",
       "Decline                                                                   \n",
       "0        msrosiebea msrosiebea outfit diary msrosiebea ...        False   \n",
       "1        hollow generationhollow playthrough blind play...        False   \n",
       "3        rust wipe wipe day horrible horrible wipe luck...        False   \n",
       "4        breyer breyerfest collecta american alligator ...        False   \n",
       "5        triple entray hip hop phora eminem king lil g ...        False   \n",
       "\n",
       "        Topic_Change  \n",
       "Source                \n",
       "Decline               \n",
       "0              False  \n",
       "1              False  \n",
       "3              False  \n",
       "4              False  \n",
       "5              False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_change(tokens_before, tokens_after):\n",
    "    # Ensure tokens are lists and not NaN or float\n",
    "    if not isinstance(tokens_before, list):\n",
    "        tokens_before = []\n",
    "    if not isinstance(tokens_after, list):\n",
    "        tokens_after = []\n",
    "        \n",
    "    set_before = set(tokens_before)\n",
    "    set_after = set(tokens_after)\n",
    "    return set_before != set_after \n",
    "\n",
    "df_pivot['Token_Change'] = df_pivot.apply(\n",
    "    lambda row: token_change(row[('Tokens', 'Before')], row[('Tokens', 'After')]), axis=1)\n",
    "\n",
    "df_pivot['Topic_Change'] = df_pivot.apply(\n",
    "    lambda row: row[('Dominant_Topic', 'Before')] != row[('Dominant_Topic', 'After')], axis=1)\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a new csv file \n",
    "df_topic_change = df_pivot.reset_index()\n",
    "df_topic_change = df_topic_change[['Decline', 'Topic_Change', 'Dominant_Topic']]\n",
    "df_topic_change.to_csv('data/df_topic_change_20_15w.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.87% of the channels changed the topic of the videos after the start of the decline.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df_topic_change['Topic_Change'].mean() * 100:.2f}% of the channels changed the topic of the videos after the start of the decline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=df_tags['Tokens'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}')\n",
    "# small df: optimum at 0.7475 with 55 topics, numwords = 9 \n",
    "# whole df: 0.6525 with 55 topics, 0.5991 with 50, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
