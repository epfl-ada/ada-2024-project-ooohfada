{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import ldamodel\n",
    "from tqdm import tqdm\n",
    "from gensim import corpora\n",
    "from src.utils.recovery_analysis_utils import str_to_list\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "decline_events = pd.read_csv('data/sampled_decline_events_with_videos.csv')\n",
    "videos = pd.read_csv('data/videos_around_declines.csv')\n",
    "\n",
    "decline_events['Videos_before'] = decline_events['Videos_before'].apply(str_to_list)\n",
    "decline_events['Videos_after'] = decline_events['Videos_after'].apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data_frame with 2 index: the index of the decline and the source (before and after)\n",
    "\n",
    "df_before = decline_events[['Videos_before']].explode('Videos_before')\n",
    "df_before['Source'] = 'Before'\n",
    "df_before = df_before.rename(columns={'Videos_before': 'Video'})\n",
    "\n",
    "df_after = decline_events[['Videos_after']].explode('Videos_after')\n",
    "df_after['Source'] = 'After'\n",
    "df_after = df_after.rename(columns={'Videos_after': 'Video'})\n",
    "\n",
    "df_tags = pd.concat([df_before, df_after], axis=0).reset_index().rename(columns={'index': 'Decline'})\n",
    "df_tags = df_tags.set_index(['Decline', 'Source'])\n",
    "\n",
    "df_tags.sort_values(by = ['Decline', 'Source'])\n",
    "df_tags = df_tags.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Video</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>Before</th>\n",
       "      <td>1684989</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684990</td>\n",
       "      <td>MsRosieBea,primark haul,primark haul august,pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684991</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684992</td>\n",
       "      <td>MsRosieBea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>1684993</td>\n",
       "      <td>MsRosieBea,red lip,get ready with me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>1889699</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889700</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889701</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,lofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889702</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,mell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>1889703</td>\n",
       "      <td>Music,beats,instrumental,right beat radio,lofi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2069978 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Video                                               Tags\n",
       "Decline Source                                                            \n",
       "0       Before  1684989                                         MsRosieBea\n",
       "        Before  1684990  MsRosieBea,primark haul,primark haul august,pr...\n",
       "        Before  1684991                                         MsRosieBea\n",
       "        Before  1684992                                         MsRosieBea\n",
       "        Before  1684993               MsRosieBea,red lip,get ready with me\n",
       "...                 ...                                                ...\n",
       "36598   After   1889699  Music,beats,instrumental,right beat radio,stra...\n",
       "        After   1889700  Music,beats,instrumental,right beat radio,late...\n",
       "        After   1889701  Music,beats,instrumental,right beat radio,lofi...\n",
       "        After   1889702  Music,beats,instrumental,right beat radio,mell...\n",
       "        After   1889703  Music,beats,instrumental,right beat radio,lofi...\n",
       "\n",
       "[2069978 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map to obtain the tags of all videos for each video before and after decline\n",
    "df_tags['Tags'] = df_tags['Video'].map(lambda video: videos.loc[video, 'tags'] if video in videos.index else None)\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,back to uni,uni outfits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,gameplay,review,guide,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,paragon,gameplay,alpha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>After</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36595</th>\n",
       "      <th>Before</th>\n",
       "      <td>Despacito accordion cover,Fonsi Despacito acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36597</th>\n",
       "      <th>After</th>\n",
       "      <td>Babbitt,Babbitt pouring,Keith Fenner,Fenner,ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Audi,Audi 2.1,Line Bore,Kenax,Line bore Kenax ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61194 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined\n",
       "Decline Source                                                   \n",
       "0       After   MsRosieBea\\nMsRosieBea,back to uni,uni outfits...\n",
       "        Before  MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...\n",
       "1       After   hollow,generationhollow,gameplay,review,guide,...\n",
       "        Before  hollow,generationhollow,paragon,gameplay,alpha...\n",
       "2       After                                                None\n",
       "...                                                           ...\n",
       "36595   Before  Despacito accordion cover,Fonsi Despacito acco...\n",
       "36597   After   Babbitt,Babbitt pouring,Keith Fenner,Fenner,ma...\n",
       "        Before  Audi,Audi 2.1,Line Bore,Kenax,Line bore Kenax ...\n",
       "36598   After   Music,beats,instrumental,right beat radio,late...\n",
       "        Before  Music,beats,instrumental,right beat radio,late...\n",
       "\n",
       "[61194 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get for each decline only 2 rows with the tags corresponding to the before and the after, handling NaNs and non-list values\n",
    "df_tags = df_tags.groupby(['Decline', 'Source'])['Tags'].apply(\n",
    "    lambda x: list(set([item for sublist in x.dropna() for item in (sublist if isinstance(sublist, list) else [sublist])]))\n",
    ").reset_index(name='Tags_combined')\n",
    "\n",
    "df_tags.set_index(['Decline', 'Source'], inplace=True)\n",
    "\n",
    "# Map the tags to a string, separating them by new lines\n",
    "df_tags['Tags_combined'] = df_tags['Tags_combined'].map(lambda tags: '\\n'.join(tags) if tags else None)\n",
    "\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "CASEFOLD = False\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_str(s):\n",
    "    if not isinstance(s, str) or not s.strip(): # Cases where s = None\n",
    "        return []\n",
    "    tokens = word_tokenize(s.lower() if CASEFOLD else s, preserve_line=True)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and lemmatizing tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61194/61194 [18:11<00:00, 56.08it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary and corpus\n",
      "Training LDA model\n",
      "(0, '0.013*\"The\" + 0.006*\"v\" + 0.005*\"\\'s\" + 0.005*\"Game\" + 0.005*\"New\"')\n",
      "(1, '0.008*\"video\" + 0.007*\"vlog\" + 0.007*\"makeup\" + 0.006*\"family\" + 0.006*\"music\"')\n",
      "(2, '0.015*\"news\" + 0.013*\"19\" + 0.012*\"rangoli\" + 0.012*\"18\" + 0.010*\"v\"')\n",
      "(3, '0.025*\"2\" + 0.022*\"game\" + 0.014*\"gameplay\" + 0.013*\"pokemon\" + 0.009*\"play\"')\n",
      "(4, '0.026*\"fortnite\" + 0.012*\"5\" + 0.010*\"game\" + 0.010*\"best\" + 0.009*\"gta\"')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,back to uni,uni outfits...</td>\n",
       "      <td>[MsRosieBea, MsRosieBea, back, uni, uni, outfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...</td>\n",
       "      <td>[MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,gameplay,review,guide,...</td>\n",
       "      <td>[hollow, generationhollow, gameplay, review, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,paragon,gameplay,alpha...</td>\n",
       "      <td>[hollow, generationhollow, paragon, gameplay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>After</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36595</th>\n",
       "      <th>Before</th>\n",
       "      <td>Despacito accordion cover,Fonsi Despacito acco...</td>\n",
       "      <td>[Despacito, accordion, cover, Fonsi, Despacito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36597</th>\n",
       "      <th>After</th>\n",
       "      <td>Babbitt,Babbitt pouring,Keith Fenner,Fenner,ma...</td>\n",
       "      <td>[Babbitt, Babbitt, pouring, Keith, Fenner, Fen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Audi,Audi 2.1,Line Bore,Kenax,Line bore Kenax ...</td>\n",
       "      <td>[Audi, Audi, 2.1, Line, Bore, Kenax, Line, bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "      <td>[Music, beat, instrumental, right, beat, radio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "      <td>[Music, beat, instrumental, right, beat, radio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined  \\\n",
       "Decline Source                                                      \n",
       "0       After   MsRosieBea\\nMsRosieBea,back to uni,uni outfits...   \n",
       "        Before  MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...   \n",
       "1       After   hollow,generationhollow,gameplay,review,guide,...   \n",
       "        Before  hollow,generationhollow,paragon,gameplay,alpha...   \n",
       "2       After                                                None   \n",
       "...                                                           ...   \n",
       "36595   Before  Despacito accordion cover,Fonsi Despacito acco...   \n",
       "36597   After   Babbitt,Babbitt pouring,Keith Fenner,Fenner,ma...   \n",
       "        Before  Audi,Audi 2.1,Line Bore,Kenax,Line bore Kenax ...   \n",
       "36598   After   Music,beats,instrumental,right beat radio,late...   \n",
       "        Before  Music,beats,instrumental,right beat radio,late...   \n",
       "\n",
       "                                                           Tokens  \n",
       "Decline Source                                                     \n",
       "0       After   [MsRosieBea, MsRosieBea, back, uni, uni, outfi...  \n",
       "        Before  [MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...  \n",
       "1       After   [hollow, generationhollow, gameplay, review, g...  \n",
       "        Before  [hollow, generationhollow, paragon, gameplay, ...  \n",
       "2       After                                                  []  \n",
       "...                                                           ...  \n",
       "36595   Before  [Despacito, accordion, cover, Fonsi, Despacito...  \n",
       "36597   After   [Babbitt, Babbitt, pouring, Keith, Fenner, Fen...  \n",
       "        Before  [Audi, Audi, 2.1, Line, Bore, Kenax, Line, bor...  \n",
       "36598   After   [Music, beat, instrumental, right, beat, radio...  \n",
       "        Before  [Music, beat, instrumental, right, beat, radio...  \n",
       "\n",
       "[61194 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizing and lemmatizing tags\")\n",
    "df_tags['Tokens'] = None\n",
    "for index, row in tqdm(df_tags.iterrows(), total=df_tags.shape[0]):\n",
    "    df_tags.at[index, 'Tokens'] = preprocess_str(row['Tags_combined'])\n",
    "\n",
    "\n",
    "# Create a dictionary and a corpus for the LDA model\n",
    "print(\"Creating dictionary and corpus\")\n",
    "dictionary = corpora.Dictionary(df_tags['Tokens'])\n",
    "corpus = [dictionary.doc2bow(token_list) for token_list in df_tags['Tokens']]\n",
    "\n",
    "print(\"Training LDA model\")\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = lda.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decline  Source\n",
      "0        After     [MsRosieBea, MsRosieBea, back, uni, uni, outfi...\n",
      "         Before    [MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...\n",
      "1        After     [hollow, generationhollow, gameplay, review, g...\n",
      "         Before    [hollow, generationhollow, paragon, gameplay, ...\n",
      "2        After                                                    []\n",
      "                                         ...                        \n",
      "36595    Before    [Despacito, accordion, cover, Fonsi, Despacito...\n",
      "36597    After     [Babbitt, Babbitt, pouring, Keith, Fenner, Fen...\n",
      "         Before    [Audi, Audi, 2.1, Line, Bore, Kenax, Line, bor...\n",
      "36598    After     [Music, beat, instrumental, right, beat, radio...\n",
      "         Before    [Music, beat, instrumental, right, beat, radio...\n",
      "Name: Tokens, Length: 61194, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(df_tags['Tokens'].head(10))\n",
    "# Replace None or NaN in Tokens with empty lists\n",
    "df_tags['Tokens'] = df_tags['Tokens'].apply(\n",
    "    lambda x: [] if x is None else x\n",
    ")\n",
    "\n",
    "\n",
    "# Flatten any nested lists in Tokens\n",
    "df_tags['Tokens'] = df_tags['Tokens'].apply(\n",
    "    lambda tokens: [item for sublist in tokens for item in sublist] if any(isinstance(i, list) for i in tokens) else tokens\n",
    "    if isinstance(tokens, list) else []\n",
    ")\n",
    "\n",
    "# Check the cleaned Tokens column\n",
    "print(df_tags['Tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokens\n",
       "<class 'list'>    61194\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags['Tokens'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary and corpus\n",
      "Training LDA model\n",
      "(0, '0.011*\"video\" + 0.011*\"music\" + 0.009*\"beat\" + 0.008*\"song\" + 0.008*\"movie\"')\n",
      "(1, '0.020*\"2\" + 0.020*\"game\" + 0.017*\"fortnite\" + 0.016*\"gameplay\" + 0.009*\"pokemon\"')\n",
      "(2, '0.030*\"news\" + 0.008*\"2019\" + 0.006*\"News\" + 0.006*\"hindi\" + 0.006*\"world\"')\n",
      "(3, '0.011*\"The\" + 0.010*\"v\" + 0.006*\"wwe\" + 0.006*\"18\" + 0.006*\"19\"')\n",
      "(4, '0.010*\"vlog\" + 0.009*\"makeup\" + 0.009*\"family\" + 0.006*\"funny\" + 0.006*\"video\"')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,back to uni,uni outfits...</td>\n",
       "      <td>[MsRosieBea, MsRosieBea, back, uni, uni, outfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...</td>\n",
       "      <td>[MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,gameplay,review,guide,...</td>\n",
       "      <td>[hollow, generationhollow, gameplay, review, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,paragon,gameplay,alpha...</td>\n",
       "      <td>[hollow, generationhollow, paragon, gameplay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>After</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36595</th>\n",
       "      <th>Before</th>\n",
       "      <td>Despacito accordion cover,Fonsi Despacito acco...</td>\n",
       "      <td>[Despacito, accordion, cover, Fonsi, Despacito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36597</th>\n",
       "      <th>After</th>\n",
       "      <td>Babbitt,Babbitt pouring,Keith Fenner,Fenner,ma...</td>\n",
       "      <td>[Babbitt, Babbitt, pouring, Keith, Fenner, Fen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Audi,Audi 2.1,Line Bore,Kenax,Line bore Kenax ...</td>\n",
       "      <td>[Audi, Audi, 2.1, Line, Bore, Kenax, Line, bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">36598</th>\n",
       "      <th>After</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "      <td>[Music, beat, instrumental, right, beat, radio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>Music,beats,instrumental,right beat radio,late...</td>\n",
       "      <td>[Music, beat, instrumental, right, beat, radio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined  \\\n",
       "Decline Source                                                      \n",
       "0       After   MsRosieBea\\nMsRosieBea,back to uni,uni outfits...   \n",
       "        Before  MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...   \n",
       "1       After   hollow,generationhollow,gameplay,review,guide,...   \n",
       "        Before  hollow,generationhollow,paragon,gameplay,alpha...   \n",
       "2       After                                                None   \n",
       "...                                                           ...   \n",
       "36595   Before  Despacito accordion cover,Fonsi Despacito acco...   \n",
       "36597   After   Babbitt,Babbitt pouring,Keith Fenner,Fenner,ma...   \n",
       "        Before  Audi,Audi 2.1,Line Bore,Kenax,Line bore Kenax ...   \n",
       "36598   After   Music,beats,instrumental,right beat radio,late...   \n",
       "        Before  Music,beats,instrumental,right beat radio,late...   \n",
       "\n",
       "                                                           Tokens  \n",
       "Decline Source                                                     \n",
       "0       After   [MsRosieBea, MsRosieBea, back, uni, uni, outfi...  \n",
       "        Before  [MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...  \n",
       "1       After   [hollow, generationhollow, gameplay, review, g...  \n",
       "        Before  [hollow, generationhollow, paragon, gameplay, ...  \n",
       "2       After                                                  []  \n",
       "...                                                           ...  \n",
       "36595   Before  [Despacito, accordion, cover, Fonsi, Despacito...  \n",
       "36597   After   [Babbitt, Babbitt, pouring, Keith, Fenner, Fen...  \n",
       "        Before  [Audi, Audi, 2.1, Line, Bore, Kenax, Line, bor...  \n",
       "36598   After   [Music, beat, instrumental, right, beat, radio...  \n",
       "        Before  [Music, beat, instrumental, right, beat, radio...  \n",
       "\n",
       "[61194 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary and a corpus for the LDA model\n",
    "print(\"Creating dictionary and corpus\")\n",
    "dictionary = corpora.Dictionary(df_tags['Tokens'])\n",
    "corpus = [dictionary.doc2bow(token_list) for token_list in df_tags['Tokens']]\n",
    "\n",
    "print(\"Training LDA model\")\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = lda.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "df_small = df_tags.head(100)\n",
    "print(df_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/q2x3vw9j7tnghtzghrscmg9w0000gn/T/ipykernel_1471/1432068147.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['Tokens'] = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and lemmatizing tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 52.11it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing and lemmatizing tags\")\n",
    "df_small['Tokens'] = None\n",
    "for index, row in tqdm(df_small.iterrows(), total=df_small.shape[0]):\n",
    "    df_small.at[index, 'Tokens'] = preprocess_str(row['Tags_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionary and corpus\n",
      "Training LDA model\n",
      "(37, '0.031*\"sticker\" + 0.027*\"stick\" + 0.027*\"planner\" + 0.027*\"etsy\" + 0.018*\"plan\" + 0.018*\"shop\" + 0.013*\"condren\" + 0.013*\"planning\" + 0.013*\"erin\"')\n",
      "(17, '0.000*\"funny\" + 0.000*\"moment\" + 0.000*\"best\" + 0.000*\"new\" + 0.000*\"van\" + 0.000*\"gameplay\" + 0.000*\"base\" + 0.000*\"let\" + 0.000*\"survival\"')\n",
      "(24, '0.000*\"Wander\" + 0.000*\"van\" + 0.000*\"life\" + 0.000*\"Kelsey\" + 0.000*\"house\" + 0.000*\"juniper\" + 0.000*\"baby\" + 0.000*\"Corbin\" + 0.000*\"rv\"')\n",
      "(44, '0.081*\"2017\" + 0.066*\"hees\" + 0.055*\"cusub\" + 0.040*\"somali\" + 0.035*\"lafoole\" + 0.030*\"niiko\" + 0.025*\"indho\" + 0.023*\"nasteexo\" + 0.020*\"ciida\"')\n",
      "(28, '0.049*\"fashion\" + 0.036*\"lookbook\" + 0.025*\"haul\" + 0.021*\"summer\" + 0.018*\"winter\" + 0.018*\"fall\" + 0.017*\"indian\" + 0.015*\"sarojini\" + 0.015*\"party\"')\n",
      "(10, '0.023*\"let\" + 0.021*\"best\" + 0.020*\"moment\" + 0.019*\"funny\" + 0.015*\"gameplay\" + 0.014*\"play\" + 0.012*\"\\'s\" + 0.011*\"new\" + 0.010*\"player\"')\n",
      "(21, '0.054*\"teacher\" + 0.047*\"hairstyle\" + 0.046*\"hair\" + 0.043*\"braid\" + 0.025*\"classroom\" + 0.018*\"tutorial\" + 0.018*\"ponytail\" + 0.016*\"easy\" + 0.015*\"first\"')\n",
      "(11, '0.071*\"eye\" + 0.069*\"makeup\" + 0.042*\"beauty\" + 0.036*\"cat\" + 0.032*\"tutorial\" + 0.027*\"ready\" + 0.026*\"smokey\" + 0.026*\"get\" + 0.021*\"liner\"')\n",
      "(18, '0.111*\"CTET\" + 0.046*\"KVS\" + 0.044*\"Live\" + 0.040*\"Study\" + 0.040*\"2019\" + 0.036*\"ctet\" + 0.035*\"Interview\" + 0.018*\"NTA\" + 0.017*\"Online\"')\n",
      "(31, '0.054*\"game\" + 0.053*\"Continue\" + 0.053*\"video\" + 0.052*\"let\" + 0.028*\"play\" + 0.027*\"\\'s\" + 0.027*\"gameplay\" + 0.027*\"episode\" + 0.027*\"funny\"')\n",
      "(0, '0.022*\"RAP\" + 0.022*\"BEAT\" + 0.020*\"xxxtentacion\" + 0.016*\"INSTRUMENTAL\" + 0.013*\"jay\" + 0.013*\"z\" + 0.013*\"TRAP\" + 0.010*\"HARD\" + 0.010*\"nightlovell\"')\n",
      "(5, '0.000*\"van\" + 0.000*\"baby\" + 0.000*\"Corbin\" + 0.000*\"life\" + 0.000*\"Wander\" + 0.000*\"new\" + 0.000*\"pregnancy\" + 0.000*\"rv\" + 0.000*\"Kelsey\"')\n",
      "(1, '0.012*\"Madredeus\" + 0.008*\"Portugal\" + 0.007*\"Braga\" + 0.006*\"Jacob\" + 0.006*\"Epic\" + 0.006*\"Christopher\" + 0.006*\"Ilusions\" + 0.006*\"Prefab\" + 0.006*\"Gurevitsch\"')\n",
      "(47, '0.000*\"All\" + 0.000*\"JJMacedo\" + 0.000*\"van\" + 0.000*\"Slow\" + 0.000*\"2018\" + 0.000*\"Wander\" + 0.000*\"Corbin\" + 0.000*\"life\" + 0.000*\"Weapons\"')\n",
      "(35, '0.000*\"game\" + 0.000*\"funny\" + 0.000*\"illuminati\" + 0.000*\"gameplay\" + 0.000*\"best\" + 0.000*\"urdu\" + 0.000*\"opener\" + 0.000*\"new\" + 0.000*\"youtube\"')\n",
      "(43, '0.090*\"pokemon\" + 0.046*\"new\" + 0.043*\"crossing\" + 0.043*\"animal\" + 0.037*\"house\" + 0.030*\"top\" + 0.024*\"game\" + 0.022*\"gameplay\" + 0.021*\"online\"')\n",
      "(14, '0.000*\"Games\" + 0.000*\"Video\" + 0.000*\"Gamers\" + 0.000*\"Rerez\" + 0.000*\"Gaming\" + 0.000*\"Game\" + 0.000*\"All\" + 0.000*\"Shane\" + 0.000*\"Wander\"')\n",
      "(19, '0.001*\"fortnite\" + 0.000*\"new\" + 0.000*\"skin\" + 0.000*\"game\" + 0.000*\"let\" + 0.000*\"gameplay\" + 0.000*\"funny\" + 0.000*\"guide\" + 0.000*\"video\"')\n",
      "(27, '0.055*\"2018\" + 0.023*\"freeski\" + 0.022*\"Mountain\" + 0.020*\"ski\" + 0.018*\"crash\" + 0.018*\"planai\" + 0.016*\"Freeski\" + 0.016*\"Festival\" + 0.016*\"pumptrack\"')\n",
      "(7, '0.001*\"fortnite\" + 0.001*\"skin\" + 0.000*\"new\" + 0.000*\"free\" + 0.000*\"season\" + 0.000*\"battle\" + 0.000*\"update\" + 0.000*\"moment\" + 0.000*\"6\"')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tags_combined</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>After</th>\n",
       "      <td>MsRosieBea\\nMsRosieBea,back to uni,uni outfits...</td>\n",
       "      <td>[MsRosieBea, MsRosieBea, back, uni, uni, outfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...</td>\n",
       "      <td>[MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>After</th>\n",
       "      <td>hollow,generationhollow,gameplay,review,guide,...</td>\n",
       "      <td>[hollow, generationhollow, gameplay, review, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>hollow,generationhollow,paragon,gameplay,alpha...</td>\n",
       "      <td>[hollow, generationhollow, paragon, gameplay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>After</th>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">55</th>\n",
       "      <th>After</th>\n",
       "      <td>Brexit,Boris Johnson,pm Johnson,Boris,Quitting...</td>\n",
       "      <td>[Brexit, Boris, Johnson, pm, Johnson, Boris, Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>james o'brien,theresa may,pm may,james o'brien...</td>\n",
       "      <td>[james, o'brien, theresa, may, pm, may, james,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">57</th>\n",
       "      <th>After</th>\n",
       "      <td>hip hop instrumental,hip hop instrumentals,jay...</td>\n",
       "      <td>[hip, hop, instrumental, hip, hop, instrumenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <td>trap beat,trap nation,n u a g e s closer,n u a...</td>\n",
       "      <td>[trap, beat, trap, nation, n, u, g, e, closer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <th>After</th>\n",
       "      <td>plan with me,etsy,stickers,sticker books,pwm,p...</td>\n",
       "      <td>[plan, etsy, sticker, sticker, book, pwm, plan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tags_combined  \\\n",
       "Decline Source                                                      \n",
       "0       After   MsRosieBea\\nMsRosieBea,back to uni,uni outfits...   \n",
       "        Before  MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...   \n",
       "1       After   hollow,generationhollow,gameplay,review,guide,...   \n",
       "        Before  hollow,generationhollow,paragon,gameplay,alpha...   \n",
       "2       After                                                None   \n",
       "...                                                           ...   \n",
       "55      After   Brexit,Boris Johnson,pm Johnson,Boris,Quitting...   \n",
       "        Before  james o'brien,theresa may,pm may,james o'brien...   \n",
       "57      After   hip hop instrumental,hip hop instrumentals,jay...   \n",
       "        Before  trap beat,trap nation,n u a g e s closer,n u a...   \n",
       "58      After   plan with me,etsy,stickers,sticker books,pwm,p...   \n",
       "\n",
       "                                                           Tokens  \n",
       "Decline Source                                                     \n",
       "0       After   [MsRosieBea, MsRosieBea, back, uni, uni, outfi...  \n",
       "        Before  [MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...  \n",
       "1       After   [hollow, generationhollow, gameplay, review, g...  \n",
       "        Before  [hollow, generationhollow, paragon, gameplay, ...  \n",
       "2       After                                                  []  \n",
       "...                                                           ...  \n",
       "55      After   [Brexit, Boris, Johnson, pm, Johnson, Boris, Q...  \n",
       "        Before  [james, o'brien, theresa, may, pm, may, james,...  \n",
       "57      After   [hip, hop, instrumental, hip, hop, instrumenta...  \n",
       "        Before  [trap, beat, trap, nation, n, u, g, e, closer,...  \n",
       "58      After   [plan, etsy, sticker, sticker, book, pwm, plan...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary and a corpus for the LDA model\n",
    "print(\"Creating dictionary and corpus\")\n",
    "dictionary = corpora.Dictionary(df_small['Tokens'])\n",
    "corpus = [dictionary.doc2bow(token_list) for token_list in df_small['Tokens']]\n",
    "\n",
    "print(\"Training LDA model\")\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=55, id2word=dictionary, passes=15)\n",
    "\n",
    "topics = lda.print_topics(num_words=9)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning topics to each document\n",
      "                                                    Tags_combined  \\\n",
      "Decline Source                                                      \n",
      "0       After   MsRosieBea\\nMsRosieBea,back to uni,uni outfits...   \n",
      "        Before  MsRosieBea,OUTFIT DIARIES\\nMsRosieBea,red lip,...   \n",
      "1       After   hollow,generationhollow,gameplay,review,guide,...   \n",
      "        Before  hollow,generationhollow,paragon,gameplay,alpha...   \n",
      "2       After                                                None   \n",
      "        Before                                               None   \n",
      "3       After   rust survival,living in a submarine,sub,base d...   \n",
      "        Before  Player unkowns battleground,battleground,battl...   \n",
      "4       After   game,PC game,computer,online,MORPEG,adventure,...   \n",
      "        Before  experience,emotional,breyerfest,breyers,horses...   \n",
      "5       After   Triple Entray,Phora,Drake,Eminem,Justin Bieber...   \n",
      "        Before  Hip hop,Triple Entray,Drake,Eminem,Logic,Phora...   \n",
      "7       After   Yasha,Yasha Jeltuhin,Cyr,Cyr Wheel,Circus,Akro...   \n",
      "        Before  Yasha,Yasha Jeltuhin,Akrosphere,Circus,Jen Mac...   \n",
      "8       After   free type beats,free untagged beats,area 51,ar...   \n",
      "        Before  impulsebeats,yung impulse,impulse beats,impuls...   \n",
      "9       After                                                None   \n",
      "        Before                                               None   \n",
      "10      After   daily vlogs,toddler,cute couple,newborn,pregna...   \n",
      "        Before  treasure,treasure hunting,exploring,underwater...   \n",
      "\n",
      "                                                           Tokens  \\\n",
      "Decline Source                                                      \n",
      "0       After   [MsRosieBea, MsRosieBea, back, uni, uni, outfi...   \n",
      "        Before  [MsRosieBea, OUTFIT, DIARIES, MsRosieBea, red,...   \n",
      "1       After   [hollow, generationhollow, gameplay, review, g...   \n",
      "        Before  [hollow, generationhollow, paragon, gameplay, ...   \n",
      "2       After                                                  []   \n",
      "        Before                                                 []   \n",
      "3       After   [rust, survival, living, submarine, sub, base,...   \n",
      "        Before  [Player, unkowns, battleground, battleground, ...   \n",
      "4       After   [game, PC, game, computer, online, MORPEG, adv...   \n",
      "        Before  [experience, emotional, breyerfest, breyers, h...   \n",
      "5       After   [Triple, Entray, Phora, Drake, Eminem, Justin,...   \n",
      "        Before  [Hip, hop, Triple, Entray, Drake, Eminem, Logi...   \n",
      "7       After   [Yasha, Yasha, Jeltuhin, Cyr, Cyr, Wheel, Circ...   \n",
      "        Before  [Yasha, Yasha, Jeltuhin, Akrosphere, Circus, J...   \n",
      "8       After   [free, type, beat, free, untagged, beat, area,...   \n",
      "        Before  [impulsebeats, yung, impulse, impulse, beat, i...   \n",
      "9       After                                                  []   \n",
      "        Before                                                 []   \n",
      "10      After   [daily, vlogs, toddler, cute, couple, newborn,...   \n",
      "        Before  [treasure, treasure, hunting, exploring, under...   \n",
      "\n",
      "                Dominant_Topic  Topic_Probability  \n",
      "Decline Source                                     \n",
      "0       After             20.0           0.481749  \n",
      "        Before            20.0           0.926696  \n",
      "1       After             54.0           0.822340  \n",
      "        Before            54.0           0.999447  \n",
      "2       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "3       After             10.0           0.999240  \n",
      "        Before            10.0           0.999116  \n",
      "4       After             34.0           0.995320  \n",
      "        Before            34.0           0.994945  \n",
      "5       After              4.0           0.901812  \n",
      "        Before             4.0           0.987081  \n",
      "7       After             11.0           0.968327  \n",
      "        Before            11.0           0.780098  \n",
      "8       After             23.0           0.562504  \n",
      "        Before             9.0           0.561162  \n",
      "9       After              NaN                NaN  \n",
      "        Before             NaN                NaN  \n",
      "10      After             36.0           0.989740  \n",
      "        Before            36.0           0.999817  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/q2x3vw9j7tnghtzghrscmg9w0000gn/T/ipykernel_1471/1577692100.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['Dominant_Topic'], df_small['Topic_Probability'] = zip(\n",
      "/var/folders/82/q2x3vw9j7tnghtzghrscmg9w0000gn/T/ipykernel_1471/1577692100.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['Dominant_Topic'], df_small['Topic_Probability'] = zip(\n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning topics to each document\")\n",
    "\n",
    "# Assign the dominant topic to each document\n",
    "def assign_dominant_topic(tokens, lda_model, dictionary):\n",
    "    if not tokens or not isinstance(tokens, list):  # Handle empty or invalid tokens\n",
    "        return None, None\n",
    "    bow = dictionary.doc2bow(tokens)  # Convert tokens to bag-of-words format\n",
    "    topic_probs = lda_model.get_document_topics(bow)  # Get topic distribution\n",
    "    if topic_probs:\n",
    "        dominant_topic, prob = max(topic_probs, key=lambda x: x[1])  # Most probable topic\n",
    "        return dominant_topic, prob\n",
    "    return None, None\n",
    "\n",
    "df_small['Dominant_Topic'], df_small['Topic_Probability'] = zip(\n",
    "    *df_small['Tokens'].apply(lambda tokens: assign_dominant_topic(tokens, lda, dictionary))\n",
    ")\n",
    "\n",
    "print(df_small.head(20))\n",
    "df_small.to_csv('df_small_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create two columns [Topic_change] and [Tokens_change] to determine if there is a difference between the tags before and after a decline. A change in tokens is used for granular analysis while a change is topics is more appropriate for detecting higher-level patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MsRosieBea MsRosieBea back uni uni outfit MsRo...</td>\n",
       "      <td>MsRosieBea OUTFIT DIARIES MsRosieBea red lip g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>hollow generationhollow gameplay review guide ...</td>\n",
       "      <td>hollow generationhollow paragon gameplay alpha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rust survival living submarine sub base design...</td>\n",
       "      <td>Player unkowns battleground battleground battl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>game PC game computer online MORPEG adventure ...</td>\n",
       "      <td>experience emotional breyerfest breyers horse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Triple Entray Phora Drake Eminem Justin Bieber...</td>\n",
       "      <td>Hip hop Triple Entray Drake Eminem Logic Phora...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 20.0   20.0   \n",
       "1                 54.0   54.0   \n",
       "3                 10.0   10.0   \n",
       "4                 34.0   34.0   \n",
       "5                  4.0    4.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        MsRosieBea MsRosieBea back uni uni outfit MsRo...   \n",
       "1        hollow generationhollow gameplay review guide ...   \n",
       "3        rust survival living submarine sub base design...   \n",
       "4        game PC game computer online MORPEG adventure ...   \n",
       "5        Triple Entray Phora Drake Eminem Justin Bieber...   \n",
       "\n",
       "                                                            \n",
       "Source                                              Before  \n",
       "Decline                                                     \n",
       "0        MsRosieBea OUTFIT DIARIES MsRosieBea red lip g...  \n",
       "1        hollow generationhollow paragon gameplay alpha...  \n",
       "3        Player unkowns battleground battleground battl...  \n",
       "4        experience emotional breyerfest breyers horse ...  \n",
       "5        Hip hop Triple Entray Drake Eminem Logic Phora...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df_small.dropna(subset=['Tokens', 'Dominant_Topic'])\n",
    "\n",
    "# Pivot the dataset, keeping 'Dominant_topic' in a separate column\n",
    "df_pivot = df_small.pivot_table(\n",
    "    index='Decline',  # The index will be based on the 'Decline'\n",
    "    columns='Source',  # We are splitting by 'Source' (Before and After)\n",
    "    values=['Tokens', 'Dominant_Topic'],  # We want both Tokens and Dominant_topic in the pivoted table\n",
    "    aggfunc={\n",
    "        'Tokens': lambda x: ' '.join([item for sublist in x for item in sublist]),  # Flatten and join the tokens\n",
    "        'Dominant_Topic': lambda x: x.mode()[0]  # Get the most frequent dominant topic (mode)\n",
    "    }\n",
    ")\n",
    "\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Dominant_Topic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tokens</th>\n",
       "      <th>Token_Change</th>\n",
       "      <th>Topic_Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th>Before</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MsRosieBea MsRosieBea back uni uni outfit MsRo...</td>\n",
       "      <td>MsRosieBea OUTFIT DIARIES MsRosieBea red lip g...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>hollow generationhollow gameplay review guide ...</td>\n",
       "      <td>hollow generationhollow paragon gameplay alpha...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rust survival living submarine sub base design...</td>\n",
       "      <td>Player unkowns battleground battleground battl...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>game PC game computer online MORPEG adventure ...</td>\n",
       "      <td>experience emotional breyerfest breyers horse ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Triple Entray Phora Drake Eminem Justin Bieber...</td>\n",
       "      <td>Hip hop Triple Entray Drake Eminem Logic Phora...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant_Topic         \\\n",
       "Source           After Before   \n",
       "Decline                         \n",
       "0                 20.0   20.0   \n",
       "1                 54.0   54.0   \n",
       "3                 10.0   10.0   \n",
       "4                 34.0   34.0   \n",
       "5                  4.0    4.0   \n",
       "\n",
       "                                                    Tokens  \\\n",
       "Source                                               After   \n",
       "Decline                                                      \n",
       "0        MsRosieBea MsRosieBea back uni uni outfit MsRo...   \n",
       "1        hollow generationhollow gameplay review guide ...   \n",
       "3        rust survival living submarine sub base design...   \n",
       "4        game PC game computer online MORPEG adventure ...   \n",
       "5        Triple Entray Phora Drake Eminem Justin Bieber...   \n",
       "\n",
       "                                                           Token_Change  \\\n",
       "Source                                              Before                \n",
       "Decline                                                                   \n",
       "0        MsRosieBea OUTFIT DIARIES MsRosieBea red lip g...        False   \n",
       "1        hollow generationhollow paragon gameplay alpha...        False   \n",
       "3        Player unkowns battleground battleground battl...        False   \n",
       "4        experience emotional breyerfest breyers horse ...        False   \n",
       "5        Hip hop Triple Entray Drake Eminem Logic Phora...        False   \n",
       "\n",
       "        Topic_Change  \n",
       "Source                \n",
       "Decline               \n",
       "0              False  \n",
       "1              False  \n",
       "3              False  \n",
       "4              False  \n",
       "5              False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_change(tokens_before, tokens_after):\n",
    "    # Ensure tokens are lists and not NaN or float\n",
    "    if not isinstance(tokens_before, list):\n",
    "        tokens_before = []\n",
    "    if not isinstance(tokens_after, list):\n",
    "        tokens_after = []\n",
    "        \n",
    "    # Compare sets of tokens\n",
    "    set_before = set(tokens_before)\n",
    "    set_after = set(tokens_after)\n",
    "    return set_before != set_after  # Change if the sets are not identical\n",
    "\n",
    "# Apply the token change function to compare the tokens before and after for each decline\n",
    "df_pivot['Token_Change'] = df_pivot.apply(\n",
    "    lambda row: token_change(row[('Tokens', 'Before')], row[('Tokens', 'After')]), axis=1)\n",
    "\n",
    "# Assuming 'Dominant_topic' columns are available for 'Before' and 'After'\n",
    "df_pivot['Topic_Change'] = df_pivot.apply(\n",
    "    lambda row: row[('Dominant_Topic', 'Before')] != row[('Dominant_Topic', 'After')], axis=1)\n",
    "\n",
    "# Verify the results\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.7055009033053095\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=df_small['Tokens'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}') # 0.7475 with 55 topics, numwords = 9\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
