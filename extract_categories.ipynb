{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "METADATA_FILENAME = 'data/yt_metadata_en.jsonl'\n",
    "\n",
    "decline_events = pd.read_csv('data/SAMPLE.csv')\n",
    "\n",
    "decline_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = decline_events['Channel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_column_to_week(df, column_name):\n",
    "    \"\"\"\n",
    "    Replace the given column by a week index,\n",
    "    starting from 0 in the earliest week found in the dataset\n",
    "\n",
    "    Parameters:\n",
    "    df  (pd.DataFrame): the dataframe in which to replace the week index\n",
    "    column_name (str): the column to replace (must be a date: 'datetime' for timeseries, 'upload_date' for metadata)\n",
    "    Return:\n",
    "    df_week (pd.DataFrame): the dataframe with the week index\n",
    "    \"\"\"\n",
    "\n",
    "    #Â The first date in the metadata is 2015-01-05, handle the time lag between the first date in metadata_helper and timeseries => keep only the data from 2015-01-05 (aligned with timeseries)\n",
    "    first_date = pd.to_datetime('2015-01-05 00:00:00')\n",
    "\n",
    "    # Get the first date in the dataset\n",
    "    if column_name == 'upload_date':\n",
    "        # Drop all raws with upload_date before 2015-01-05\n",
    "        df = df[df['upload_date'] >= first_date]\n",
    "\n",
    "    # Compute the week index\n",
    "    df.loc[:,'week'] = df[column_name].apply(lambda x: (x - first_date).days // 7)\n",
    "\n",
    "    df_week = df.drop(column_name, axis=1)\n",
    "\n",
    "    # Remove the datetime column\n",
    "    return df_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file 'videos.jsonl' in batches of 5000 rows, and add the categories to the result dataframe when the videos is between start - TIME_BEFORE and end + TIME_AFTER\n",
    "CHUNK_SIZE = 5000\n",
    "\n",
    "# remove SettingWithCopyWarning: \n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "i = 0\n",
    "for chunk in pd.read_json(METADATA_FILENAME, lines=True, chunksize=CHUNK_SIZE):\n",
    "\n",
    "    try:\n",
    "        init_shape = int(chunk.shape[0])\n",
    "        \n",
    "        chunk = chunk[chunk['channel_id'].isin(channels)]\n",
    "        \n",
    "        chunk.loc[:, 'upload_date'] = pd.to_datetime(chunk['upload_date'])\n",
    "\n",
    "        chunk = map_column_to_week(chunk, 'upload_date')\n",
    "\n",
    "        # keep the videos that are in the time frame for the respective channel\n",
    "        mask = []\n",
    "        for video in chunk.itertuples():\n",
    "            channel_mask = decline_events['Channel'].isin([video.channel_id])\n",
    "            start_mask = decline_events['Start'] - decline_events['Duration'] <= video.week\n",
    "            end_mask = decline_events['End'] >= video.week\n",
    "\n",
    "            mask.append(decline_events[channel_mask & start_mask & end_mask].shape[0] > 0)\n",
    "\n",
    "        kept = chunk[mask]\n",
    "\n",
    "        if kept.shape[0] == 0:\n",
    "            print(f'Chunk {i} (lines {i*CHUNK_SIZE} to {(i+1)*CHUNK_SIZE}): 0/{init_shape} videos kept')\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        cols_of_interest = ['channel_id', 'week', 'tags', 'duration']\n",
    "\n",
    "        kept = kept[cols_of_interest]\n",
    "\n",
    "        print(f'Chunk {i} (lines {i*CHUNK_SIZE} to {(i+1)*CHUNK_SIZE}): {kept.shape[0]}/{init_shape} videos kept')\n",
    "\n",
    "        kept.to_csv(f'data/categories.csv', index=False, mode='a', header=False)\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Error in chunk {i} (lines {i*CHUNK_SIZE} to {(i+1)*CHUNK_SIZE}): {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
