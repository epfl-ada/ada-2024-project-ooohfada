{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import datetime\n",
    "from ipywidgets import interact, Dropdown, SelectionSlider, widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src/data'))\n",
    "\n",
    "from dataloader import *\n",
    "from bbdataset_preprocessing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Load the data](#I.-Load-the-data)\n",
    "    - [A. Load All Channel Data](#1.-Load-All-Channel-Data)\n",
    "    - [B. Load Selected Bad Buzz Channel Data](#2.-Load-Selected-Bad-Buzz-Channel-Data)\n",
    "2. [Data Analysis on Bad Buzz Data](#II.-Data-Analysis-on-Bad-Buzz-Data)\n",
    "    - [A. Subscribers Analysis](#A.-Subscribers-Analysis)\n",
    "    - [B. Views Analysis around Detected Bad Buzz](#B.-Views-Analysis-around-Detected-Bad-Buzz)\n",
    "    - [C. Likes/Dislikes Analysis around Detected Bad Buzz ](#C.-Likes/Dislikes-Analysis-around-Detected-Bad-Buzz)\n",
    "    - [D. Activity around the BB](#D.-Activity-around-the-BB)\n",
    "3. [Data Analysis on All Dataset](#III.-Data-Analysis-On-All-Dataset)\n",
    "4. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- i have a dataset that gathers all channels that have suffered at least once of a bad buzz \n",
    "- GOAL : find a general method that can find the bad buzz\n",
    "- HOW CAN I DO IT ? \n",
    "    - i have the list of channels with the date of the bb \n",
    "    - i need to find these dates thanks to a statistical analysis \n",
    "    - i have for each pair of channel and week index : \n",
    "        - `category`\n",
    "        - `views` : Total number of views the channel had this week.\n",
    "        - `delta_views` : Delta views obtained this week.\n",
    "        - `subs` : Total number of subscribers the channel had this week.\n",
    "        - `delta_subs` : Delta subscribers obtained this week.\n",
    "        - `number of videos` : Total number of videos the channel had this week.\n",
    "        - `delta_videos` : Delta videos obtained this week.\n",
    "        - `activity` : number of videos posted this week \n",
    "        - `view_count` => number of views f viedos posted\n",
    "        - `like_count` => number of likes on pposted video \n",
    "        - `dislike_count` => number of dislikes on pposted video "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAD BUZZ INDICATORS : \n",
    "    - increase in dislike count \n",
    "    - drop in subscriber growth or loss of subscribers\n",
    "    - decrease in views or view growth \n",
    "    - changes in likes/dislikes ratios : higher dislikes ratio \n",
    "    - changes in number of videos posted, fewer views despite more content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Channel Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_index_to_date(week_index):\n",
    "    # Base date corresponding to week index 0\n",
    "    base_date = datetime.datetime(2015, 1, 5)\n",
    "    \n",
    "    # Calculate the date by adding the number of weeks to the base date\n",
    "    target_date = base_date + datetime.timedelta(weeks=week_index)\n",
    "    \n",
    "    return target_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomment the next line if we need to update the preprocessed data \n",
    "# update_processed_data(verbose=True)\n",
    "original_data = load_processed_data(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_channels = original_data.reset_index()['channel'].nunique()\n",
    "print(f'Number of channels : {nb_channels}')\n",
    "print(f'Columns name :\\n {original_data.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_week_index_original = original_data.reset_index()['week'].min()\n",
    "max_week_index_original = original_data.reset_index()['week'].max()\n",
    "\n",
    "print(f'The minimum week index is {min_week_index_original} and corresponds to the date : {week_index_to_date(min_week_index_original)}')\n",
    "print(f'The maximum week index is {max_week_index_original} and corresponds to the date : {week_index_to_date(max_week_index_original)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Selected Bad Buzz Channel Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomment the next line if we need to update the preprocessed data \n",
    "# update_processed_bb_timeseries(verbose=True)\n",
    "data = load_bb_timeseries_processed(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_channels = data.reset_index()['channel'].nunique()\n",
    "print(f'Number of channels : {nb_channels}')\n",
    "print(f'Columns name :\\n {data.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_week_index = data.reset_index()['week'].min()\n",
    "max_week_index = data.reset_index()['week'].max()\n",
    "\n",
    "print(f'The minimum week index is {min_week_index} and corresponds to the date : {week_index_to_date(min_week_index)}')\n",
    "print(f'The maximum week index is {max_week_index} and corresponds to the date : {week_index_to_date(max_week_index)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Analysis On BB Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Subscribers Analysis\n",
    "The first stop of our analysis is to detect the sudden subscriber losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plot for each channel the evolution of the number of subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : convert the week indices into real date ? \n",
    "# TODO : check title and axes label \n",
    "\n",
    "def plot_subs_by_channel(channel, df): \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    df = df.xs(channel, level='channel')\n",
    "    \n",
    "    sns.lineplot(data=df, x='week', y='subs', label='Subscribers')\n",
    "    \n",
    "    plt.xlabel(\"Week index\")\n",
    "    plt.ylabel(\"Subscribers\")\n",
    "    plt.title(f\"Subscriber Trends for {channel}\")\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SelectionSlider widget for selecting channels\n",
    "channel_selector = SelectionSlider(\n",
    "    options=data.index.get_level_values('channel').unique(),\n",
    "    description='Channel:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_subs = widgets.interactive_output(plot_subs_by_channel, {'channel': channel_selector, 'df': widgets.fixed(data)})\n",
    "display(channel_selector, interactive_plot_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rolling average analysis\n",
    "Since the big YouTube channels in our dataset typically experience consistent subscriber growth, they rarely face actual decreases in their total subscriber count. However, a significant slowdown in the growth rate can still be considered a negative event, as it may indicate potential issues such as reduced engagement or a negative reception by the audience. To detect these sharp declines in subscriber growth, we compare the actual growth rate (`delta_subs`) against the rolling average growth rate (`rolling_growth_rate`).\\\n",
    "The rolling average acts as a smoothed baseline, calculated using a defined window (we arbitrarily used a `ROLLING_WINDOW` of 20 weeks), which helps to identify deviations from the expected trend. When the actual growth rate falls below the rolling average, it suggests that the channel's performance has dipped relative to its typical trend. This comparison enables us to highlight periods of concern where the channel's momentum weakens, which could signal the start of a \"bad buzz\" or other negative factors impacting channel performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : faire une méthode pour calculer la rolling avg et détecter le début des bb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLLING_WINDOW = 20\n",
    "THRESHOLD_BB = 0 #TODO: try to modify it so that it doesn't detect the small BB\n",
    "\n",
    "data['rolling_growth_rate'] = data.groupby('channel')['delta_subs'].transform(lambda x: x.rolling(ROLLING_WINDOW, min_periods=1).mean())\n",
    "data['growth_diff'] = data['delta_subs'] - data['rolling_growth_rate']\n",
    "\n",
    "# Detection of period where growth_rate < rolling_growth_rate\n",
    "data['is_bad_buzz'] = data['growth_diff'] < THRESHOLD_BB\n",
    "# Create a DataFrame that contains only the starting week of each BBC\n",
    "bad_buzz_starts = []\n",
    "\n",
    "# For loop to detect the starting week of BB\n",
    "for channel in data.reset_index()['channel'].unique():\n",
    "    channel_data = data.reset_index()[data.reset_index()['channel'] == channel]\n",
    "    \n",
    "    # Identify indices where BB has started\n",
    "    for i in range(1, len(channel_data)):\n",
    "        if channel_data['is_bad_buzz'].iloc[i] and not channel_data['is_bad_buzz'].iloc[i-1]:\n",
    "            bad_buzz_starts.append({'channel': channel, 'week': channel_data['week'].iloc[i]})\n",
    "\n",
    "bad_buzz_df = pd.DataFrame(bad_buzz_starts).reset_index()[['channel', 'week']]\n",
    "\n",
    "max_nb_bb = bad_buzz_df.groupby('channel').count()['week'].max()\n",
    "print(f'A channel has a maximum of {max_nb_bb}')\n",
    "\n",
    "bad_buzz_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the periods of concern, we save in the dataframe `bad_buzz_df` the first week index of the period where growth_rate < rolling_growth_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_growth_rate(channel, df, bad_buzz_df): \n",
    "    df_plot = df.xs(channel, level='channel')\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    sns.lineplot(data=df_plot, x='week', y='delta_subs', label='Delta Subscribers', color='blue')\n",
    "    sns.lineplot(data=df_plot, x='week', y='rolling_growth_rate', label='Rolling Growth Rate', color='orange')\n",
    "    \n",
    "    plt.fill_between(df_plot.reset_index()['week'], df_plot['delta_subs'], df_plot['rolling_growth_rate'], \n",
    "                    where=(df_plot['delta_subs'] < df_plot['rolling_growth_rate']), \n",
    "                    color='red', alpha=0.3, label='Potential Bad Buzz')\n",
    "\n",
    "    # Plot vertical lines for bad buzz weeks\n",
    "    bad_buzz_weeks = bad_buzz_df[bad_buzz_df['channel'] == channel]['week']\n",
    "    for week in bad_buzz_weeks:\n",
    "        plt.axvline(x=week, color='green', linestyle='--', alpha=0.7, label='Bad Buzz' if week == bad_buzz_weeks.iloc[0] else \"\")\n",
    "    \n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Growth Rate')\n",
    "    plt.title(f'Delta Subscribers and Rolling Growth Rate for Channel {channel}')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_subs_roll_avg = widgets.interactive_output(plot_rolling_growth_rate, {'channel': channel_selector,\n",
    "                                                                                       'df': widgets.fixed(data), \n",
    "                                                                                       'bad_buzz_df': widgets.fixed(bad_buzz_df)})\n",
    "display(channel_selector, interactive_plot_subs_roll_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we detected periods of concern that are potential \"bad buzz\", we want to see if the change of growth rate correlates with other engagement metrics or events. Specifically, we aim to identify relationships between these slowdowns in subscriber growth and various possible influencing factors such as:\n",
    "- Number of views\n",
    "- Like/Dislike ratio\n",
    "- Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Views Analysis around Detected Bad Buzz \n",
    "During this part of the analysis, we want to visualize changes in views around the periods of interest detected previously, to explore the behavior of `delta_views` around the identified periods for each YouTube channel.\\\n",
    "We use the `define_periods` function to divide the data into:\n",
    "- Pre-buzz: 10 weeks leading up to the bad buzz event.\n",
    "- During-buzz: The 8-week period starting from the bad buzz week.\n",
    "- Post-buzz: The following 10 to 20 weeks post-buzz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Delta Views Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_views_around_bad_buzz(channel, df, bad_buzz_df): \n",
    "    df_plot = df.xs(channel, level='channel').reset_index()\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    sns.lineplot(data=df_plot, x='week', y='delta_views', label='Delta Views', color='blue')\n",
    "    \n",
    "    # Plot vertical lines for bad buzz weeks\n",
    "    bad_buzz_weeks = bad_buzz_df[bad_buzz_df['channel'] == channel]['week']\n",
    "    for week in bad_buzz_weeks:\n",
    "        plt.axvline(x=week, color='green', linestyle='--', alpha=0.7, label='Bad Buzz' if week == bad_buzz_weeks.iloc[0] else \"\")\n",
    "    \n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Views')\n",
    "    plt.title(f'Views Around Bad Buzz Weeks for Channel {channel}')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_views = widgets.interactive_output(plot_views_around_bad_buzz, {'channel': channel_selector, \n",
    "                                                                                'df': widgets.fixed(data), \n",
    "                                                                                'bad_buzz_df': widgets.fixed(bad_buzz_df)})\n",
    "display(channel_selector, interactive_plot_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. One Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_week_indices(df, week):\n",
    "    df['relative_week'] = df['week'] - week\n",
    "    return df\n",
    "\n",
    "def define_periods(df):\n",
    "    pre_buzz = df[(df['relative_week'] < 0) & (df['relative_week'] >= -10)]\n",
    "    during_buzz = df[(df['relative_week'] >= 0) & (df['relative_week'] <= 8)]\n",
    "    post_buzz = df[(df['relative_week'] > 10) & (df['relative_week'] <= 20)]\n",
    "    return pre_buzz, during_buzz, post_buzz\n",
    "\n",
    "def calculate_averages(pre_buzz, during_buzz, post_buzz):\n",
    "    avg_pre_buzz_views = pre_buzz['delta_views'].mean()\n",
    "    avg_during_buzz_views = during_buzz['delta_views'].mean()\n",
    "    avg_post_buzz_views = post_buzz['delta_views'].mean()\n",
    "    return avg_pre_buzz_views, avg_during_buzz_views, avg_post_buzz_views\n",
    "\n",
    "def perform_t_test(pre_buzz, during_buzz):\n",
    "    t_stat, p_value = ttest_ind(during_buzz['delta_views'], pre_buzz['delta_views'], equal_var=False)\n",
    "    return p_value\n",
    "\n",
    "def plot_results(ax, df, avg_pre_buzz_views, week, p_value, rolling_window=10, pos_p_value=-0.15):\n",
    "    ax.plot(df['relative_week'], df['delta_views'], label='Delta Views', color='blue')\n",
    "    ax.plot(df['relative_week'], df['delta_views'].rolling(rolling_window).mean(), label='Rolling Avg (Views)', color='orange')\n",
    "    ax.axvline(x=0, color='red', linestyle='--', label='Bad Buzz Start')\n",
    "    ax.axhline(y=avg_pre_buzz_views, color='green', linestyle='--', label='Pre-Buzz Avg')\n",
    "    \n",
    "    ax.set_title(f\"Delta Views around Bad Buzz (Week {week})\")\n",
    "    ax.set_xlabel('Weeks')\n",
    "    ax.set_ylabel('Delta Views')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add p-value text\n",
    "    ax.text(0.5, pos_p_value, f'p-value: {p_value:.4f}', transform=ax.transAxes, ha='center', va='center')\n",
    "\n",
    "def analyze_views_around_bad_buzz(channel, df, bad_buzz_df, pos_p_value=-0.25):\n",
    "    df_plot = df.xs(channel, level='channel').reset_index()\n",
    "    bad_buzz_weeks = bad_buzz_df[bad_buzz_df['channel'] == channel]['week']\n",
    "    \n",
    "    fig, axes = plt.subplots(6, 4, figsize=(15, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, week in enumerate(bad_buzz_weeks):\n",
    "        df_plot = normalize_week_indices(df_plot, week)\n",
    "        pre_buzz, during_buzz, post_buzz = define_periods(df_plot)\n",
    "        avg_pre_buzz_views, avg_during_buzz_views, avg_post_buzz_views = calculate_averages(pre_buzz, during_buzz, post_buzz)\n",
    "        \n",
    "        p_value = perform_t_test(pre_buzz, during_buzz)\n",
    "        \n",
    "        plot_results(axes[i], df_plot, avg_pre_buzz_views, week, p_value, pos_p_value=pos_p_value)\n",
    "        \n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pre-buzz, during-buzz, and post-buzz periods of each detected period, we compute the average `delta_views` and perform a t-test to determine if the change in views during the bad buzz is statistically significant compared to the pre-buzz period. The `analyze_views_around_bad_buzz` function iterates over each detected bad buzz week, to analyze how delta_views changed around these periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pew_die_pie = data.xs('UC-lHJZR3Gqxm24_Vd_AJ5Yw', level='channel').reset_index()\n",
    "pew_die_pie_bb_weeks = bad_buzz_df[bad_buzz_df['channel'] == 'UC-lHJZR3Gqxm24_Vd_AJ5Yw']['week']\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, week in enumerate(pew_die_pie_bb_weeks):\n",
    "    df_plot = normalize_week_indices(pew_die_pie, week)\n",
    "    pre_buzz, during_buzz, post_buzz = define_periods(df_plot)\n",
    "    avg_pre_buzz_views, avg_during_buzz_views, avg_post_buzz_views = calculate_averages(pre_buzz, during_buzz, post_buzz)\n",
    "    \n",
    "    p_value = perform_t_test(pre_buzz, during_buzz)\n",
    "    \n",
    "    plot_results(axes[i], df_plot, avg_pre_buzz_views, week, p_value)\n",
    "    \n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. All Channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_views_roll_avg = widgets.interactive_output(analyze_views_around_bad_buzz, {'channel': channel_selector, \n",
    "                                                                                            'df': widgets.fixed(data),\n",
    "                                                                                            'bad_buzz_df': widgets.fixed(bad_buzz_df)})\n",
    "display(channel_selector, interactive_plot_views_roll_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a few of the detected periods of interest seem to be correlated with a significant change of views.\\\n",
    "We hypothesize the following:\n",
    "\n",
    "- **Loss of Interest**: When audience engagement decreases due to a gradual loss of interest or content fatigue, we expect a sustained decrease in delta_views. This pattern reflects a natural decline in audience engagement without significant external attention. In this case, we are not expecting an important change between the `delta_views` averages of the `pre_buzz` and the `during_buzz` periods. It could be interesting to further explore this option by comparing the `pre_buzz` and `post_buzz` averages.\n",
    "\n",
    "- **Bad Buzz Event**: Conversely, when audience loss is triggered by a negative event (e.g., public backlash or negative media coverage), we hypothesize that there will be an initial temporary spike in views. This increase results from heightened public interest or curiosity, as viewers seek to understand or react to the controversy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach used in this part helps us understand whether significant shifts in views occur around the identified bad buzz periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Likes/Dislikes Analysis Around Detected Bad Buzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After investigating the number of views, we would now like to see if the number dislikes increase and if the number of likes decreases when a channel has a sudden drop of growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalize the timeline around each identified bad buzz event\n",
    "- Compare metrics for pre-buzz, during-buzz, and post-buzz periods:\n",
    "    - Pre-Buzz: Let's say the 10 weeks leading up to the bad buzz\n",
    "    - During Buzz: The week of the bad buzz and the 4 weeks following it\n",
    "    - Post-Buzz: The 10 weeks after the initial bad buzz period\n",
    "- Key metrics:\n",
    "    - like_count: The number of likes received during a specific week\n",
    "    - dislike_count: The number of dislikes received during a specific week\n",
    "    - Like/Dislike Ratio: Calculated as like_count / (like_count + dislike_count)\n",
    "\n",
    "- Hypothesis Testing\n",
    "    - Hypothesis: During a bad buzz, dislike_count should increase, and like_count or the like/dislike ratio should decrease\n",
    "You can verify this by comparing averages and performing statistical tests to see if there’s a significant change in these metrics during the bad buzz period compared to the pre-buzz period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_engagement_averages(pre_buzz, during_buzz):\n",
    "    avg_pre_likes = pre_buzz['like_count'].mean()\n",
    "    avg_pre_dislikes = pre_buzz['dislike_count'].mean()\n",
    "    avg_pre_ratio = (pre_buzz['like_count'] / (pre_buzz['like_count'] + pre_buzz['dislike_count'])).mean()\n",
    "\n",
    "    avg_during_likes = during_buzz['like_count'].mean()\n",
    "    avg_during_dislikes = during_buzz['dislike_count'].mean()\n",
    "    avg_during_ratio = (during_buzz['like_count'] / (during_buzz['like_count'] + during_buzz['dislike_count'])).mean()\n",
    "    \n",
    "    return avg_pre_likes, avg_pre_dislikes, avg_pre_ratio, avg_during_likes, avg_during_dislikes, avg_during_ratio\n",
    "\n",
    "def perform_engagement_t_tests(pre_buzz, during_buzz):\n",
    "    t_stat_dislikes, p_value_dislikes = ttest_ind(during_buzz['dislike_count'], pre_buzz['dislike_count'], equal_var=False)\n",
    "    t_stat_ratio, p_value_ratio = ttest_ind(\n",
    "        during_buzz['like_count'] / (during_buzz['like_count'] + during_buzz['dislike_count']),\n",
    "        pre_buzz['like_count'] / (pre_buzz['like_count'] + pre_buzz['dislike_count']),\n",
    "        equal_var=False\n",
    "    )\n",
    "    return p_value_dislikes, p_value_ratio\n",
    "\n",
    "def plot_engagement_results(ax, df, week, p_value_dislikes, p_value_ratio, pos_p_value=-0.15):\n",
    "    sns.lineplot(data=df, x='relative_week', y='like_count', label='Likes', color='blue', ax=ax)\n",
    "    sns.lineplot(data=df, x='relative_week', y='dislike_count', label='Dislikes', color='orange', ax=ax)\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(df['relative_week'], (df['like_count'] / (df['like_count'] + df['dislike_count'])).rolling(5).mean(), label='Like/Dislike Ratio', color='purple')\n",
    "    \n",
    "    ax.axvline(x=0, color='green', linestyle='--', label='Bad Buzz Start')\n",
    "    \n",
    "    ax.set_title(f\"Likes, Dislikes, and Ratio around Bad Buzz (Week {week})\")\n",
    "    ax.set_xlabel('Weeks Relative to Bad Buzz')\n",
    "    ax.set_ylabel('Engagement Counts')\n",
    "    ax2.set_ylabel('Like/Dislike Ratio')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add p-value text\n",
    "    ax.text(0.5, pos_p_value, f'p-value (dislikes): {p_value_dislikes:.4f}, p-value (ratio): {p_value_ratio:.4f}', transform=ax.transAxes, ha='center', va='center')\n",
    "\n",
    "def analyze_engagement_around_bad_buzz(channel, df, bad_buzz_df, pos_p_value=-0.25):\n",
    "    df_plot = df.xs(channel, level='channel').reset_index()\n",
    "    bad_buzz_weeks = bad_buzz_df[bad_buzz_df['channel'] == channel]['week']\n",
    "    \n",
    "    fig, axes = plt.subplots(6, 4, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, week in enumerate(bad_buzz_weeks):\n",
    "        df_plot = normalize_week_indices(df_plot, week)\n",
    "        pre_buzz, during_buzz, post_buzz = define_periods(df_plot)\n",
    "        \n",
    "        p_value_dislikes, p_value_ratio = perform_engagement_t_tests(pre_buzz, during_buzz)\n",
    "        \n",
    "        plot_engagement_results(axes[i], df_plot, week, p_value_dislikes, p_value_ratio, pos_p_value)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. One Channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, week in enumerate(pew_die_pie_bb_weeks):\n",
    "    df_plot = normalize_week_indices(pew_die_pie, week)\n",
    "    pre_buzz, during_buzz, post_buzz = define_periods(df_plot)\n",
    "    avg_pre_likes, avg_pre_dislikes, avg_pre_ratio, avg_during_likes, avg_during_dislikes, avg_during_ratio = calculate_engagement_averages(pre_buzz, during_buzz)\n",
    "    \n",
    "    p_value_dislikes, p_value_ratio = perform_engagement_t_tests(pre_buzz, during_buzz)\n",
    "    \n",
    "    plot_engagement_results(axes[i], df_plot, week, p_value_dislikes, p_value_ratio)\n",
    "    \n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION : If you see a significant increase in dislikes and a drop in the like/dislike ratio during the bad buzz period (confirmed by low p-values from the t-tests), this would support your hypothesis. The visualizations can also help you understand whether the patterns are consistent across channels or unique to specific cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very strange to have the same like/dislike ratio before a BB and after a BB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. All Channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_likes_dislikes = widgets.interactive_output(analyze_engagement_around_bad_buzz, {'channel': channel_selector, \n",
    "                                                                                   'df': widgets.fixed(data), \n",
    "                                                                                   'bad_buzz_df': widgets.fixed(bad_buzz_df)})\n",
    "display(channel_selector, interactive_plot_likes_dislikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Activity around the BB \n",
    "In this part, we want to see if the activity of a youtube channel and its growth are correlated.\\\n",
    "HYPOTHESIS:\n",
    "- An activity lower than usual could induce a down-turn of the growth\n",
    "- A period of slower growth could be followed by a high- or low- activity, depending on the strategy of the youtube channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activity_averages(pre_buzz, during_buzz, post_buzz):\n",
    "    avg_pre_activity = pre_buzz['activity'].mean()\n",
    "    avg_during_activity = during_buzz['activity'].mean()\n",
    "    avg_post_activity = post_buzz['activity'].mean()\n",
    "    return avg_pre_activity, avg_during_activity, avg_post_activity\n",
    "\n",
    "def perform_activity_t_tests(pre_buzz, during_buzz):\n",
    "    t_stat_activity, p_value_activity = ttest_ind(during_buzz['activity'], pre_buzz['activity'], equal_var=False)\n",
    "    return p_value_activity\n",
    "\n",
    "def plot_activity_results(ax, df, avg_pre_activity, week, p_value_activity, pos_p_value=-0.15):\n",
    "    sns.lineplot(data=df, x='relative_week', y='activity', label='Activity', color='blue', ax=ax)\n",
    "    ax.axvline(x=0, color='green', linestyle='--', label='Bad Buzz Start')\n",
    "    ax.axhline(y=avg_pre_activity, color='red', linestyle='--', label='Pre-Buzz Avg')\n",
    "    \n",
    "    ax.set_title(f\"Activity around Bad Buzz (Week {week})\")\n",
    "    ax.set_xlabel('Weeks Relative to Bad Buzz')\n",
    "    ax.set_ylabel('Number of Videos Posted')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.text(0.5, pos_p_value, f'p-value (dislikes): {p_value_activity:.4f}', transform=ax.transAxes, ha='center', va='center')\n",
    "\n",
    "def analyze_activity_around_bad_buzz(channel, df, bad_buzz_df, pos_p_value=-0.25):\n",
    "    df_plot = df.xs(channel, level='channel').reset_index()\n",
    "    bad_buzz_weeks = bad_buzz_df[bad_buzz_df['channel'] == channel]['week']\n",
    "    \n",
    "    fig, axes = plt.subplots(6, 4, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, week in enumerate(bad_buzz_weeks):\n",
    "        df_plot = normalize_week_indices(df_plot, week)\n",
    "        pre_buzz, during_buzz, post_buzz = define_periods(df_plot)\n",
    "        avg_pre_activity, avg_during_activity, avg_post_activity = calculate_activity_averages(pre_buzz, during_buzz, post_buzz)\n",
    "        \n",
    "        p_value_activity = perform_activity_t_tests(pre_buzz, during_buzz)\n",
    "        \n",
    "        plot_activity_results(axes[i], df_plot, avg_pre_activity, week, p_value_activity, pos_p_value)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For One Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, week in enumerate(pew_die_pie_bb_weeks):\n",
    "    df_plot = normalize_week_indices(pew_die_pie, week)\n",
    "    pre_buzz, during_buzz, post_buzz = define_periods(df_plot)\n",
    "    avg_pre_activity, avg_during_activity, avg_post_activity = calculate_activity_averages(pre_buzz, during_buzz, post_buzz)\n",
    "    \n",
    "    p_value_activity = perform_activity_t_tests(pre_buzz, during_buzz)\n",
    "    \n",
    "    plot_activity_results(axes[i], df_plot, avg_pre_activity, week, p_value_activity)\n",
    "    \n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For All Channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_activity = widgets.interactive_output(analyze_activity_around_bad_buzz, {'channel': channel_selector, \n",
    "                                                                                          'df': widgets.fixed(data), \n",
    "                                                                                          'bad_buzz_df': widgets.fixed(bad_buzz_df)})\n",
    "display(channel_selector, interactive_plot_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data Analysis On All Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Subscribers Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribers plot for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SelectionSlider widget for selecting channels\n",
    "channel_selector_original = SelectionSlider(\n",
    "    options=original_data.index.get_level_values('channel').unique(),\n",
    "    description='Channel:',\n",
    "    disabled=False\n",
    ")\n",
    "interactive_plot_original = widgets.interactive_output(plot_subs_by_channel, {'channel': channel_selector_original, 'df': widgets.fixed(original_data)})\n",
    "display(channel_selector_original, interactive_plot_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rolling average analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller_original_data = original_data[['delta_subs']]\n",
    "# smaller_original_data = smaller_original_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROLLING_WINDOW = 20\n",
    "\n",
    "# # Initialize the new column with NaN values of the appropriate data type\n",
    "# smaller_original_data['rolling_growth_rate'] = np.nan\n",
    "\n",
    "# # Get the unique channels\n",
    "# channels = smaller_original_data['channel'].unique()\n",
    "\n",
    "# # Iterate over each channel and calculate the rolling mean\n",
    "# for channel in tqdm(channels, desc=\"Calculating rolling growth rate\"):\n",
    "#     channel_data = smaller_original_data[smaller_original_data['channel'] == channel]\n",
    "#     rolling_mean = channel_data['delta_subs'].rolling(ROLLING_WINDOW, min_periods=1).mean()\n",
    "#     smaller_original_data.loc[smaller_original_data['channel'] == channel, 'rolling_growth_rate'] = rolling_mean\n",
    "\n",
    "# smaller_original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROLLING_WINDOW = 20\n",
    "# THRESHOLD_BB = 0 #TODO: try to modify it so that it doesn't detect the small BB\n",
    "\n",
    "# original_data['rolling_growth_rate'] = original_data.groupby('channel')['delta_subs'].transform(lambda x: x.rolling(ROLLING_WINDOW, min_periods=1).mean())\n",
    "# original_data['growth_diff'] = original_data['delta_subs'] - original_data['rolling_growth_rate']\n",
    "\n",
    "# # Detection of period where growth_rate < rolling_growth_rate\n",
    "# original_data['is_bad_buzz'] = original_data['growth_diff'] < THRESHOLD_BB\n",
    "# # Create a DataFrame that contains only the starting week of each BBC\n",
    "# bad_buzz_starts = []\n",
    "\n",
    "# # For loop to detect the starting week of BB\n",
    "# for channel in original_data.reset_index()['channel'].unique():\n",
    "#     channel_data = original_data.reset_index()[original_data.reset_index()['channel'] == channel]\n",
    "    \n",
    "#     # Identify indices where BB has started\n",
    "#     for i in range(1, len(channel_data)):\n",
    "#         if channel_data['is_bad_buzz'].iloc[i] and not channel_data['is_bad_buzz'].iloc[i-1]:\n",
    "#             bad_buzz_starts.append({'channel': channel, 'week': channel_data['week'].iloc[i]})\n",
    "\n",
    "# bad_buzz_df_original = pd.DataFrame(bad_buzz_starts).reset_index()[['channel', 'week']]\n",
    "\n",
    "# bad_buzz_df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_rgr = pd.read_csv('df_with_rgr.tsv', sep='\\t')\n",
    "events = pd.read_csv('event.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_rgr.head()\n",
    "print(df_with_rgr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_selector_original = SelectionSlider(\n",
    "    options=original_data.index.get_level_values('channel').unique(),\n",
    "    description='Channel:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_subs_roll_avg_original = widgets.interactive_output(plot_rolling_growth_rate, {'channel': channel_selector_original, \n",
    "                                                                                                'df': widgets.fixed(original_data), \n",
    "                                                                                                'bad_buzz_df': widgets.fixed(bad_buzz_df_original)})\n",
    "display(channel_selector_original, interactive_plot_subs_roll_avg_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Views Analysis around Detected BB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Delta Views Evolution In General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_views_original = widgets.interactive_output(plot_views_around_bad_buzz, {'channel': channel_selector_original, \n",
    "                                                                                        'df': widgets.fixed(original_data), \n",
    "                                                                                        'bad_buzz_df': widgets.fixed(bad_buzz_df_original)})\n",
    "display(channel_selector_original, interactive_plot_views_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Delta Views Evolution in around BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_views_roll_avg_original = widgets.interactive_output(analyze_views_around_bad_buzz, {'channel': channel_selector_original, \n",
    "                                                                                                    'df': widgets.fixed(original_data), \n",
    "                                                                                                    'bad_buzz_df': widgets.fixed(bad_buzz_df_original)})\n",
    "display(channel_selector_original, interactive_plot_views_roll_avg_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Likes/Dislikes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_likes_dislikes_original = widgets.interactive_output(analyze_engagement_around_bad_buzz, {'channel': channel_selector_original, \n",
    "                                                                                                            'df': widgets.fixed(original_data), \n",
    "                                                                                                            'bad_buzz_df': widgets.fixed(bad_buzz_df_original)})\n",
    "display(channel_selector_original, interactive_plot_likes_dislikes_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Activity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_plot_activity_original = widgets.interactive_output(analyze_activity_around_bad_buzz, {'channel': channel_selector_original, \n",
    "                                                                                                    'df': widgets.fixed(original_data), \n",
    "                                                                                                    'bad_buzz_df': widgets.fixed(bad_buzz_df_original)})\n",
    "display(channel_selector_original, interactive_plot_activity_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Various Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "bad_buzz_df.head()\n",
    "print(\"Shape of bad_buzz_df: \", bad_buzz_df.shape, \n",
    "      \"\\nShape of data: \", data.shape, \n",
    "      \"\\nShape of df_with_rgr: \", df_with_rgr.shape, \n",
    "      \"\\nShape of original df: \", original_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge the two dataframes `df_with_rgr`and `original_df` on their common columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_with_rgr.columns)\n",
    "\n",
    "original_data = original_data.reset_index()\n",
    "print(original_data.columns)\n",
    "\n",
    "# Now merge the DataFrames on 'week' and 'channel'\n",
    "merged_df = df_with_rgr.merge(original_data, on=['category', 'views', 'delta_views', 'subs', 'delta_subs', 'videos',\n",
    "       'delta_videos', 'activity', 'view_count', 'like_count', 'dislike_count'])\n",
    "\n",
    "# Display the shape of the merged DataFrame to confirm the result\n",
    "print(f\"Shape of merged DataFrame: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(events, on=['channel'])\n",
    "print(merged_df.columns)\n",
    "print(\"Shape of our df: \", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=merged_df, x='category', y='delta_subs', color='skyblue', showfliers=False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Boxplot of Delta Subs by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Delta Subs')\n",
    "plt.show()\n",
    "\n",
    "bad_buzz_counts = merged_df[merged_df['is_bad_buzz']].groupby('category').size()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bad_buzz_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Bar Plot of Bad Buzz by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Bad Buzz Occurrences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(merged_df['week_y'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Bad Buzz Over Time')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of Bad Buzz Events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "numeric_df = merged_df.select_dtypes(include=['number'])  # Select only numeric columns\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=merged_df, x='delta_views', y='delta_subs', hue='category')\n",
    "plt.title('Scatter Plot of Delta Views vs. Delta Subs')\n",
    "plt.xlabel('Delta Views')\n",
    "plt.ylabel('Delta Subs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=data, x='activity', y='delta_subs', hue='category')\n",
    "plt.title('Activity vs. Subscriber Growth')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Delta Subs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(merged_df, vars=['views', 'delta_views', 'subs', 'delta_subs', 'activity'], hue='is_bad_buzz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_df[['category', 'channel', 'week_y']].drop_duplicates()\n",
    "data = data.rename(columns={'week_y': 'event'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = data['category'].value_counts()\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Total Number of Events by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
