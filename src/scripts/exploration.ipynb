{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from ipywidgets import interact, Dropdown, SelectionSlider, widgets\n",
    "from preprocessing import apply_complete_preprocessing\n",
    "from datasets import load_processed_data, update_processed_data\n",
    "from bbdatasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data in chunks of 1000: 100%|█████████▉| 18604/18604.825 [01:19<00:00, 234.57it/s]/Users/nathangromb/opt/miniconda3/lib/python3.9/site-packages/tqdm/std.py:524: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "Loading data in chunks of 1000: 100%|██████████| 18605/18604.825 [01:19<00:00, 233.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# decomment the next line if we need to update the preprocessed data \n",
    "# update_processed_data(verbose=True)\n",
    "original_data = load_processed_data(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data in chunks of 1000: 6it [00:00, 239.92it/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5030 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# decomment the next line if we need to update the preprocessed data \n",
    "# update_processed_bb_timeseries(verbose=True)\n",
    "data = load_bb_timeseries_processed(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- i have a dataset that gathers all channels that have suffered at least once of a bad buzz \n",
    "- GOAL : find a general method that can find the bad buzz\n",
    "- HOW CAN I DO IT ? \n",
    "    - i have the list of channels with the date of the bb \n",
    "    - i need to find these dates thanks to a statistical analysis \n",
    "    - i have for each pair of channel and week index : \n",
    "        - category\n",
    "        - views : Total number of views the channel had this week.\n",
    "        - delta_views : Delta views obtained this week.\n",
    "        - subs : Total number of subscribers the channel had this week.\n",
    "        - delta_subs : Delta subscribers obtained this week.\n",
    "        - number of videos : Total number of videos the channel had this week.\n",
    "        - delta_videos : Delta videos obtained this week.\n",
    "        - activity : number of videos posted this week \n",
    "        - view_count => number of views f viedos posted\n",
    "        - like_count => number of likes on pposted video \n",
    "        - dislike_count => number of dislikes on pposted video "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAD BUZZ INDICATORS : \n",
    "    - increase in dislike count \n",
    "    - drop in subscriber growth or loss of subscribers\n",
    "    - decrease in views or view growth \n",
    "    - changes in likes/dislikes ratios : higher dislikes ratio \n",
    "    - changes in number of videos posted, fewer views despite more content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 channels in the new dataset\n"
     ]
    }
   ],
   "source": [
    "nb_channels = data.reset_index()['channel'].nunique()\n",
    "print(f'There are {nb_channels} channels in the new dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Statistical Analysis : anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Compute rolling averages and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avg_anomaly_detection(data, metric, window_size, bound_size): \n",
    "    data[f'moving_avg_{metric}'] = data.groupby('channel')[metric].transform(lambda x: x.rolling(window_size, min_periods=1).mean())\n",
    "    data[f'moving_std_{metric}'] = data.groupby('channel')[metric].transform(lambda x: x.rolling(window_size, min_periods=1).std())\n",
    "    data[f'upper_bound_{metric}'] = data[f'moving_avg_{metric}'] + bound_size * data[f'moving_std_{metric}']\n",
    "    data[f'lower_bound_{metric}'] = data[f'moving_avg_{metric}'] - bound_size * data[f'moving_std_{metric}']\n",
    "    data[f'is_anomaly_{metric}'] = data[metric] < data[f'lower_bound_{metric}']\n",
    "    return data.drop(columns=[f'moving_avg_{metric}', f'moving_std_{metric}', f'upper_bound_{metric}', f'lower_bound_{metric}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels with subs anomalies : 16\n",
      "Number of channels with views anomalies : 8\n",
      "Number of channels with dislikes anomalies : 7\n"
     ]
    }
   ],
   "source": [
    "# TODO : need to play with values \n",
    "WINDOW_SIZE = 8\n",
    "BOUND_SIZE = 2\n",
    "\n",
    "df_moving_avg = data.copy()\n",
    "df_moving_avg = moving_avg_anomaly_detection(df_moving_avg, 'subs', WINDOW_SIZE, BOUND_SIZE)\n",
    "df_moving_avg = moving_avg_anomaly_detection(df_moving_avg, 'views', WINDOW_SIZE, BOUND_SIZE)\n",
    "df_moving_avg = moving_avg_anomaly_detection(df_moving_avg, 'dislike_count', WINDOW_SIZE, BOUND_SIZE)\n",
    "\n",
    "channels_with_subs_anomalies = df_moving_avg.groupby('channel').filter(lambda x : x['is_anomaly_subs'].sum() > 0)\n",
    "channels_with_views_anomalies = df_moving_avg.groupby('channel').filter(lambda x : x['is_anomaly_views'].sum() > 0)\n",
    "channels_with_dislikes_anomalies = df_moving_avg.groupby('channel').filter(lambda x : x['is_anomaly_dislike_count'].sum() > 0)\n",
    "\n",
    "nb_channels_with_subs_anomalies = channels_with_subs_anomalies.reset_index()['channel'].nunique()\n",
    "nb_channels_with_views_anomalies = channels_with_views_anomalies.reset_index()['channel'].nunique()\n",
    "nb_channels_with_dislikes_anomalies = channels_with_dislikes_anomalies.reset_index()['channel'].nunique()\n",
    "\n",
    "print(f'Number of channels with subs anomalies : {nb_channels_with_subs_anomalies}')\n",
    "print(f'Number of channels with views anomalies : {nb_channels_with_views_anomalies}')\n",
    "print(f'Number of channels with dislikes anomalies : {nb_channels_with_dislikes_anomalies}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fdc3e503534651b2a46f607160efdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Channel:', options=('UC-lHJZR3Gqxm24_Vd_AJ5Yw', 'UC0v-tlzsn…"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_moving_avg(channel):\n",
    "    df_plot = df_moving_avg.xs(channel, level='channel')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_plot, x='week', y='subs')\n",
    "    plt.scatter(df_plot[df_plot['is_anomaly_subs']].reset_index()['week'], \n",
    "                df_plot[df_plot['is_anomaly_subs']]['subs'],\n",
    "                color='red', label='moving_avg_anomalies', marker='+')\n",
    "    plt.title(f'Channel: {channel}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting channels\n",
    "channel_selector = widgets.SelectionSlider(\n",
    "    options=df_moving_avg.index.get_level_values('channel').unique(),\n",
    "    description='Channel:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Display the widget and update the plot when the selection changes\n",
    "widgets.interactive(plot_moving_avg, channel=channel_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Z-score analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-scores are useful because they indicate how many standard deviations a value is from the mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_anomaly_detection(data, metric, threshold): \n",
    "    data[f'z_score_{metric}'] = data.groupby('channel')[metric].transform(lambda x : stats.zscore(x.dropna()))\n",
    "    data[f'is_anomaly_{metric}'] = data[f'z_score_{metric}'] < -threshold\n",
    "    print(data.xs('UCDsO-0Yo5zpJk575nKXgMVA', level='channel')[[f'z_score_{metric}', 'delta_subs']])\n",
    "    return data.drop(columns=[f'z_score_{metric}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      z_score_delta_subs    delta_subs\n",
      "week                                  \n",
      "92                   NaN           NaN\n",
      "93             -0.886522   1328.250000\n",
      "94             -1.267507  -1249.549223\n",
      "95             -1.208361   -849.362236\n",
      "96             -1.088993    -41.697917\n",
      "...                  ...           ...\n",
      "243             0.534616  10943.875000\n",
      "244             0.486878  10620.875000\n",
      "245            -0.040638   7051.625000\n",
      "246            -0.614432   3169.250000\n",
      "247            -1.015916    452.750000\n",
      "\n",
      "[153 rows x 2 columns]\n",
      "      z_score_delta_views    delta_subs\n",
      "week                                   \n",
      "92                    NaN           NaN\n",
      "93              -1.118289   1328.250000\n",
      "94               0.467402  -1249.549223\n",
      "95              -1.112394   -849.362236\n",
      "96              -1.234311    -41.697917\n",
      "...                   ...           ...\n",
      "243              1.369339  10943.875000\n",
      "244              1.139081  10620.875000\n",
      "245              0.466373   7051.625000\n",
      "246              0.050000   3169.250000\n",
      "247             -0.788046    452.750000\n",
      "\n",
      "[153 rows x 2 columns]\n",
      "Number of channels with subs anomalies : 25\n",
      "Number of channels with views anomalies : 30\n",
      "Number of channels that have both subs and views anomalies : 12\n"
     ]
    }
   ],
   "source": [
    "Z_SCORE_THRESHOLD = 1\n",
    "\n",
    "df_z_score = data.copy()\n",
    "df_z_score = z_score_anomaly_detection(df_z_score, 'delta_subs', Z_SCORE_THRESHOLD)\n",
    "df_z_score = z_score_anomaly_detection(df_z_score, 'delta_views', Z_SCORE_THRESHOLD)\n",
    "\n",
    "channels_with_subs_z_score_anomalies = df_z_score.groupby('channel').filter(lambda x : x['is_anomaly_delta_subs'].sum() > 1)\n",
    "channels_with_views_z_score_anomalies = df_z_score.groupby('channel').filter(lambda x : x['is_anomaly_delta_views'].sum() > 1)\n",
    "\n",
    "nb_channels_with_subs_z_score_anomalies = channels_with_subs_z_score_anomalies.reset_index()['channel'].nunique()\n",
    "nb_channels_with_views_z_score_anomalies = channels_with_views_z_score_anomalies.reset_index()['channel'].nunique()\n",
    "nb_channels_subs_views_anomalies = df_z_score[(df_z_score['is_anomaly_delta_subs']) & \n",
    "                                              (df_z_score['is_anomaly_delta_views'])].reset_index()['channel'].nunique()\n",
    "\n",
    "print(f'Number of channels with subs anomalies : {nb_channels_with_subs_z_score_anomalies}')\n",
    "print(f'Number of channels with views anomalies : {nb_channels_with_views_z_score_anomalies}')\n",
    "print(f'Number of channels that have both subs and views anomalies : {nb_channels_subs_views_anomalies}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "channel\n",
       "UC-lHJZR3Gqxm24_Vd_AJ5Yw     2\n",
       "UC0v-tlzsn0QZwJnkiaUSJVQ    23\n",
       "UC1r4VtVE__5K6c_L_3Vlxxg     8\n",
       "UC2e0bNZ6CzT-Xvr070VaGsw     3\n",
       "UC6-NBhOCP8DJqnpZE4TNE-A     1\n",
       "UCAq9s3QQVCDMvg1iWQBVtxQ     1\n",
       "UCBHu7LsKiwiYViR230RtsCA    16\n",
       "UCDsO-0Yo5zpJk575nKXgMVA    39\n",
       "UCEHf6KUY7Zw7hlXQ7hDemwQ     7\n",
       "UCJZ7f6NQzGKZnFXzFW9y9UQ     4\n",
       "UCKGiTasUqLcZUuUjQiyKotw     6\n",
       "UCKMugoa0uHpjUuq14yOpagw     3\n",
       "UCKlhpmbHGxBE6uw9B_uLeqQ    17\n",
       "UCV9_KinVpV-snHe3C3n1hvA     1\n",
       "UCVJK2AT3ea5RTXNRjX_kz8A    13\n",
       "UCVtFOytbRpEvzLjvqGG5gxQ     2\n",
       "UCWwWOFsW68TqXE-HZLC3WIA    13\n",
       "UCX6OQ3DkcsbYNE6H8uQQuVA     0\n",
       "UCXhSCMRRPyxSoyLSPFxK7VA    10\n",
       "UC_DptbqTndVt_Im3KkuIK5Q     0\n",
       "UCcgVECVN4OKV6DH1jLkqmcA    11\n",
       "UCdJdEguB1F1CiYe7OEi3SBg     1\n",
       "UCdoLeDxfcGwvj_PRl7TLTzQ     4\n",
       "UCiH828EtgQjTyNIMH6YiOSw     8\n",
       "UClWD8su9Sk6GzZDwy9zs3_w    19\n",
       "UCnEn0EUV13IR-_TK7fiIp3g     2\n",
       "UCoiIt_v1D-6z75LmrdIU2aw    23\n",
       "UCtVubfONoPpn4kNuuZ1h6iQ     0\n",
       "UCucot-Zp428OwkyRm2I7v2Q     2\n",
       "UCxJf49T4iTO_jtzWX3rW_jg    23\n",
       "UCy_YiQx1t8oOgz74QIB4Jrw    13\n",
       "UCzJIliq68IHSn-Kwgjeg2AQ     0\n",
       "UCzKc6JrWSt_67UpEYIefrJQ     7\n",
       "Name: is_anomaly_delta_subs, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score_anomalies_count = df_z_score.groupby('channel')['is_anomaly_delta_subs'].sum()\n",
    "z_score_anomalies_count.columns = ['channel', 'num_anomalies']\n",
    "z_score_anomalies_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I keep a threshold of 2 (meaning that i keeo values that are away of 2 std or more from the mean) then i can get almost all the channels and in each channel i detect more than 1 anomaly \n",
    "\n",
    "It would be now interesting to look at the date of the anomaly to understand effetively is there was a bad buzz\n",
    "\n",
    "I could first plot the number of subs along the time and add a point where an anomaly was detected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea09fa260a6a40e7959895b27f41f761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Channel:', options=('UC-lHJZR3Gqxm24_Vd_AJ5Yw', 'UC0v-tlzsn…"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_z_score(channel):\n",
    "    df_plot = df_z_score.xs(channel, level='channel')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_plot, x='week', y='subs')\n",
    "    plt.scatter(df_plot[df_plot['is_anomaly_delta_subs']].reset_index()['week'], \n",
    "                df_plot[df_plot['is_anomaly_delta_subs']]['subs'],\n",
    "                color='red', label='z_scores_anomalies', marker='+')\n",
    "    plt.title(f'Channel: {channel}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting channels\n",
    "channel_selector = widgets.SelectionSlider(\n",
    "    options=df_z_score.index.get_level_values('channel').unique(),\n",
    "    description='Channel:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Display the widget and update the plot when the selection changes\n",
    "widgets.interactive(plot_z_score, channel=channel_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Delta delta derivative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of channels with subs anomalies : 31\n",
      "Number of channels with views anomalies : 29\n",
      "Number of channels that have both subs and views anomalies : 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f35ec336ecd47dda76b1b905fd0214d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='Channel:', options=('UC-lHJZR3Gqxm24_Vd_AJ5Yw', 'UC0v-tlzsn…"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delta_delta_anomaly_detection(data, metric, threshold):\n",
    "    data[f'delta_{metric}'] = data.groupby('channel')[metric].diff()\n",
    "    data[f'delta_delta_z_score_{metric}'] = data.groupby('channel')[f'delta_{metric}'].transform(lambda x : stats.zscore(x.dropna()))\n",
    "    data[f'is_anomaly_delta_{metric}'] = data[f'delta_delta_z_score_{metric}'] < -threshold\n",
    "    return data.drop(columns=[f'delta_{metric}', f'delta_delta_z_score_{metric}'])\n",
    "\n",
    "DELTA_DELTA_THRESHOLD = 2\n",
    "\n",
    "df_delta_delta = data.copy()\n",
    "df_delta_delta = delta_delta_anomaly_detection(df_delta_delta, 'delta_subs', DELTA_DELTA_THRESHOLD)\n",
    "df_delta_delta = delta_delta_anomaly_detection(df_delta_delta, 'delta_views', DELTA_DELTA_THRESHOLD)\n",
    "\n",
    "channels_with_subs_delta_delta_anomalies = df_delta_delta.groupby('channel').filter(lambda x : x['is_anomaly_delta_delta_subs'].sum() > 1)\n",
    "channels_with_views_delta_delta_anomalies = df_delta_delta.groupby('channel').filter(lambda x : x['is_anomaly_delta_delta_views'].sum() > 1)\n",
    "\n",
    "nb_channels_with_subs_delta_delta_anomalies = channels_with_subs_delta_delta_anomalies.reset_index()['channel'].nunique()\n",
    "nb_channels_with_views_delta_delta_anomalies = channels_with_views_delta_delta_anomalies.reset_index()['channel'].nunique()\n",
    "nb_channels_subs_views_delta_delta_anomalies = df_delta_delta[(df_delta_delta['is_anomaly_delta_delta_subs']) &\n",
    "                                                                (df_delta_delta['is_anomaly_delta_delta_views'])].reset_index()['channel'].nunique()\n",
    "\n",
    "print(f'Number of channels with subs anomalies : {nb_channels_with_subs_delta_delta_anomalies}')\n",
    "print(f'Number of channels with views anomalies : {nb_channels_with_views_delta_delta_anomalies}')\n",
    "print(f'Number of channels that have both subs and views anomalies : {nb_channels_subs_views_delta_delta_anomalies}')\n",
    "\n",
    "def plot_delta_delta(channel):\n",
    "    df_plot = df_delta_delta.xs(channel, level='channel')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=df_plot, x='week', y='subs')\n",
    "    plt.scatter(df_plot[df_plot['is_anomaly_delta_delta_subs']].reset_index()['week'],\n",
    "                df_plot[df_plot['is_anomaly_delta_delta_subs']]['subs'],\n",
    "                color='red', label='delta_delta_anomalies', marker='+')\n",
    "    plt.title(f'Channel: {channel}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create a dropdown widget for selecting channels\n",
    "channel_selector = widgets.SelectionSlider(\n",
    "    options=df_z_score.index.get_level_values('channel').unique(),\n",
    "    description='Channel:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Display the widget and update the plot when the selection changes\n",
    "widgets.interactive(plot_delta_delta, channel=channel_selector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
